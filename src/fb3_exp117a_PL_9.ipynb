{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 62228,
     "status": "ok",
     "timestamp": 1663840881115,
     "user": {
      "displayName": "Rashmi Banthia",
      "userId": "08241869107709835428"
     },
     "user_tz": 240
    },
    "id": "pqJOSKiP_rNx",
    "outputId": "f64942d2-7723-4f27-ff7b-3972bcc60845"
   },
   "outputs": [],
   "source": [
    "# This is AWP + exp67 seed=2022, maxlen=512, PL + decreasing max len + last 8 hidden layers\n",
    "# Psuedo labels for this code is here - https://www.kaggle.com/code/rashmibanthia/fb3-psuedo-labels-1-from-exp47b/notebook?scriptVersionId=107695932 \n",
    "# these were generated from exp47.\n",
    "\n",
    "# This has 5 fold split of fb1 dataset - https://www.kaggle.com/code/rashmibanthia/fb3-fb1-merged\n",
    "\n",
    "colab=False\n",
    "vastai=False\n",
    "local = True\n",
    "\n",
    "if local: \n",
    "  data_dir =  \"/home/rashmi/Documents/kaggle/feedback3/\"\n",
    "  \n",
    "if colab:\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/gdrive')\n",
    "  data_dir = 'gdrive/MyDrive/kaggle/2022/feedback3'\n",
    "\n",
    "  !mkdir -p feedback1\n",
    "  !cp gdrive/MyDrive/kaggle/2022/feedback_prize/data/train.zip feedback1\n",
    "  !unzip -oqq gdrive/MyDrive/kaggle/2022/feedback_prize/data/train.zip -d feedback1/\n",
    "\n",
    "  FEEDBACK1_TRAIN_CSV = 'gdrive/MyDrive/kaggle/2022/feedback_prize/data/train.csv'\n",
    "  FEEDBACK1_TRAIN_DIR = 'feedback1/train/'\n",
    "\n",
    "  !pip install wandb > /dev/null\n",
    "  !pip install tokenizers > /dev/null\n",
    "  !pip install transformers > /dev/null\n",
    "  !pip install sentencepiece > /dev/null\n",
    "  !pip install tez > /dev/null\n",
    "  !pip install datasets > /dev/null\n",
    "    \n",
    "if vastai:\n",
    "    data_dir = '/workspace/feedback3/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 924,
     "status": "ok",
     "timestamp": 1663840882024,
     "user": {
      "displayName": "Rashmi Banthia",
      "userId": "08241869107709835428"
     },
     "user_tz": 240
    },
    "id": "jJVksZ1-DYkP"
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Directory settings\n",
    "# ====================================================\n",
    "import os\n",
    "EXP_NAME = 'exp117a_PL_9'\n",
    "OUTPUT_DIR = f'{data_dir}/src/models_' + EXP_NAME + \"/\"\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105,
     "referenced_widgets": [
      "93c3f000ef5a45b3862685d0ac6492fe",
      "23f6b46983dc4451b2c4246046719b29",
      "94d72c0994df48df95ef6d0d14128262",
      "2160a30916b44bde803b27ab7e1c0764",
      "8493f01d50ce4baa87643e47574aa12c",
      "bfde2b802d83416db5dfd57fcc2d563e",
      "3c6043d1f6a14957b137d103046809d9",
      "17ac416ac3764b2ab31fafd66e6b63f4",
      "de56444578ff470cba1e93d40147c3aa",
      "ef291d1776eb4dbb97e2ad476e372c0a",
      "f19414fc4d044c6e8612f31c2c834be4"
     ]
    },
    "executionInfo": {
     "elapsed": 5749,
     "status": "ok",
     "timestamp": 1663840887770,
     "user": {
      "displayName": "Rashmi Banthia",
      "userId": "08241869107709835428"
     },
     "user_tz": 240
    },
    "id": "ln0u93px_wRQ",
    "outputId": "e1800879-a23d-4b52-9794-2e03a496ca27"
   },
   "outputs": [],
   "source": [
    "import os, gc, pickle, math, time, random, copy, json\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from tqdm import tqdm\n",
    "import multiprocessing\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from sklearn.model_selection import GroupKFold, StratifiedGroupKFold\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from datasets import Dataset\n",
    "\n",
    "# Mixed precision in Pytorch\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "# For SWA\n",
    "from torch.optim.swa_utils import AveragedModel, SWALR\n",
    "\n",
    "from transformers import AutoConfig, AutoTokenizer, AutoModel\n",
    "from transformers import get_cosine_schedule_with_warmup, get_linear_schedule_with_warmup, AdamW\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.23.1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 149,
     "referenced_widgets": [
      "901d751c9df543e0bdf8a2f27be1e8ea",
      "c4552d78739243ac91711e6fbcd971e9",
      "88728d80d4ef411e939dc5a21633b4ef",
      "f1550ac128f1452a8276a8b05f87ec08",
      "e9a0915b711a4fb3a219dcb5aa2c8a72",
      "b6835dfe966347a0b1e085777d1d4aaa",
      "67ccfd480cc84e51ae6e3a81e160a2ed",
      "bfc1f40195904b829481005969009522",
      "00cb0f09326f48648bc77717defcbed4",
      "76d156eff0174e2b8b24d08b42bcf226",
      "ae9a9998768047bbb2188527d56af1da",
      "786737122d5141008f877783f44c6de4",
      "4a604395aadc4f6b88d69a09078b7b63",
      "29aa0cc29eb14cc5a546cb6d759e2edf",
      "7e3a87338f1045bea1473b81b5a22566",
      "a162e763f30941f484e6c75870a379cf",
      "64126e0a2a8e45e191f7564dc9b20cda",
      "e9b72bce0ad244ee848df3b7501e2447",
      "fb22f13fdb474f1793c59e0cd6b13980",
      "09d48089a9cb491a884907c5fb0cd321",
      "8c2122b040554d3781cf1164176d8b95",
      "02853e01c2c34d0f971302091ba489de",
      "6de2ce67f2ba44cbbbc7c9877f6bbdd5",
      "d1942a9b9c5a4d18b6bf90b2626ffefc",
      "037f022ba7ba4191b0421562f8432320",
      "20005452fb7a4fcbb812da475138f4b6",
      "386d12e9047e4463ac23eee35656025a",
      "7d63101f3e784294babe163546b61ec4",
      "f7a2b7f7d0964fcca88c4a821797de51",
      "1389b90c58d5417ea8da9c183f6c8ea0",
      "84a0247a3c80472ba8f42a17b13772a5",
      "a117379727864b86bc3f92743fd46bb4",
      "657c1434e09642758450169035fbd250"
     ]
    },
    "executionInfo": {
     "elapsed": 4043,
     "status": "ok",
     "timestamp": 1663840891806,
     "user": {
      "displayName": "Rashmi Banthia",
      "userId": "08241869107709835428"
     },
     "user_tz": 240
    },
    "id": "2QtgOrkF__MQ",
    "outputId": "6d7392af-06b2-42e7-afa3-7af799821c88"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "class Config:\n",
    "    # General settings\n",
    "    competition_name = 'FeedbackPrize3'\n",
    "    seed = 2022 #42\n",
    "    debug = False\n",
    "    train = True\n",
    "    n_fold = 5\n",
    "    print_freq = 100\n",
    "    wandb = True\n",
    "    val_strategy = \"batch\"\n",
    "    val_steps = 250 #300\n",
    "    # For model\n",
    "    # model='gdrive/MyDrive/kaggle/2022/feedback2/pretrain/models_pretrain_debertav3large-expA/deberta-v3-large'\n",
    "    # tokenizer_path='gdrive/MyDrive/kaggle/2022/feedback2/pretrain/models_pretrain_debertav3large-expA/deberta-v3-large/tokenizer'\n",
    "    model = \"microsoft/deberta-v3-large\"\n",
    "    tokenizer_path = \"microsoft/deberta-v3-large\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "    config = AutoConfig.from_pretrained(model)\n",
    "    config.output_hidden_states = True\n",
    "    config.hidden_dropout_prob = 0.\n",
    "    config.attention_probs_dropout_prob = 0.\n",
    "    \n",
    "    scheduler='cosine'\n",
    "    trn_fold = [0,1,2,3,4]\n",
    "    max_len = 512\n",
    "    batch_size = 4\n",
    "    num_workers = os.cpu_count()\n",
    "    # For training\n",
    "    apex = True\n",
    "    gradient_checkpointing = True\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    epochs = 4\n",
    "    gradient_accumulation_steps = 1.\n",
    "    max_grad_norm = 1000\n",
    "    label_smoothing = 0.03\n",
    "    num_labels=6\n",
    "    # Optimizer\n",
    "    lr = 1e-5\n",
    "    weight_decay = 1e-2\n",
    "    encoder_lr = 1e-5\n",
    "    decoder_lr = 1e-5\n",
    "    min_lr = 1e-6\n",
    "    eps = 1e-6\n",
    "    betas = (0.9, 0.999)\n",
    "    # Scheduler\n",
    "    scheduler_type = 'cosine'    # 'linear', 'cosine'\n",
    "    if scheduler_type == 'cosine':\n",
    "        num_cycles = 0.5\n",
    "    num_warmup_steps = 100\n",
    "    batch_scheduler = True\n",
    "    gpu_optimize_config_adam = False\n",
    "    TRAIN_FOLDS = f'{data_dir}/input/train_folds.csv'\n",
    "    # For AWP\n",
    "    use_awp = True\n",
    "    if use_awp:\n",
    "        start_awp_epoch = 1 \n",
    "        awp_score_check = 0.49\n",
    "        adv_lr = 2e-5\n",
    "        adv_eps = 1e-3 #1e-2\n",
    "#         adv_step = 1\n",
    "    else:\n",
    "        start_awp_epoch = epochs + 1\n",
    "\n",
    "CFG = Config()\n",
    "CFG.tokenizer.add_special_tokens({'additional_special_tokens': ['[PARAGRAPH]']})\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "true_cols = ['cohesion', 'syntax', 'vocabulary','phraseology', 'grammar', 'conventions']\n",
    "pred_cols = ['pred_cohesion', 'pred_syntax', 'pred_vocabulary','pred_phraseology', 'pred_grammar', 'pred_conventions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 177
    },
    "executionInfo": {
     "elapsed": 4621,
     "status": "ok",
     "timestamp": 1663840896423,
     "user": {
      "displayName": "Rashmi Banthia",
      "userId": "08241869107709835428"
     },
     "user_tz": 240
    },
    "id": "O5ve3TspKKf3",
    "outputId": "5924d472-c09d-45cb-e9ab-9f1c7d9273f5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrashmi\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/rashmi/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/rashmi/Documents/kaggle/feedback3/src/wandb/run-20221116_220751-2aq9z4qq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/rashmi/FeedbackPrize3/runs/2aq9z4qq\" target=\"_blank\">microsoft/deberta-v3-large</a></strong> to <a href=\"https://wandb.ai/rashmi/FeedbackPrize3\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ====================================================\n",
    "# wandb\n",
    "# ====================================================\n",
    "if CFG.wandb:\n",
    "    \n",
    "    import wandb\n",
    "\n",
    "    try:\n",
    "        # from kaggle_secrets import UserSecretsClient\n",
    "        # user_secrets = UserSecretsClient()\n",
    "        # secret_value_0 = user_secrets.get_secret(\"wandb_api\")\n",
    "        # wandb.login(key=secret_value_0)\n",
    "        wandb.login(key='yourkeyhere')\n",
    "        anony = None\n",
    "    except:\n",
    "        anony = \"must\"\n",
    "        print('If you want to use your W&B account, go to Add-ons -> Secrets and provide your W&B access token. Use the Label name as wandb_api. \\nGet your W&B access token from here: https://wandb.ai/authorize')\n",
    "\n",
    "\n",
    "    def class2dict(f):\n",
    "        return dict((name, getattr(f, name)) for name in dir(f) if not name.startswith('__'))\n",
    "\n",
    "    run = wandb.init(project=CFG.competition_name, \n",
    "                     name=CFG.model,\n",
    "                     config=class2dict(CFG),\n",
    "                     group=CFG.model,\n",
    "                     job_type=EXP_NAME, #\"train\",\n",
    "                     anonymous=anony)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1663840896424,
     "user": {
      "displayName": "Rashmi Banthia",
      "userId": "08241869107709835428"
     },
     "user_tz": 240
    },
    "id": "Ymyu-O4QCe5Y"
   },
   "outputs": [],
   "source": [
    "\"\"\"# Random seed\"\"\"\n",
    "\n",
    "def seed_everything(seed, use_cuda = True):\n",
    "    np.random.seed(seed) # cpu vars\n",
    "    torch.manual_seed(seed) # cpu  vars\n",
    "    random.seed(seed) # Python\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed) # Python hash building\n",
    "    if use_cuda:\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed) # gpu vars\n",
    "        torch.backends.cudnn.deterministic = True  #needed\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "def get_logger(filename=OUTPUT_DIR+'train'):\n",
    "    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=f\"{filename}.log\")\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "LOGGER = get_logger()\n",
    "\n",
    "seed_everything(CFG.seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>token_length</th>\n",
       "      <th>kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>Phones Modern humans today are always on their...</td>\n",
       "      <td>442</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A8445CABFECE</td>\n",
       "      <td>Phones &amp; Driving Drivers should not be able to...</td>\n",
       "      <td>242</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6B4F7A0165B9</td>\n",
       "      <td>Cell Phone Operation While Driving The ability...</td>\n",
       "      <td>364</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E05C7F5C1156</td>\n",
       "      <td>People are debating whether if drivers should ...</td>\n",
       "      <td>671</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50B3435E475B</td>\n",
       "      <td>Texting and driving Over half of drivers in to...</td>\n",
       "      <td>420</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15137</th>\n",
       "      <td>0814426B27DF</td>\n",
       "      <td>Most people ask more than one person for advic...</td>\n",
       "      <td>512</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15138</th>\n",
       "      <td>8F4B595CF9E7</td>\n",
       "      <td>Do you ever want more opinions and options whe...</td>\n",
       "      <td>639</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15139</th>\n",
       "      <td>6B5809C83978</td>\n",
       "      <td>Has anyone ever gave you advice? Was the advic...</td>\n",
       "      <td>411</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15140</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>There has been at least one point in everyone'...</td>\n",
       "      <td>647</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15141</th>\n",
       "      <td>4C471936CD75</td>\n",
       "      <td>In ancient times, and also still today in some...</td>\n",
       "      <td>1166</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15142 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            text_id                                          full_text  \\\n",
       "0      423A1CA112E2  Phones Modern humans today are always on their...   \n",
       "1      A8445CABFECE  Phones & Driving Drivers should not be able to...   \n",
       "2      6B4F7A0165B9  Cell Phone Operation While Driving The ability...   \n",
       "3      E05C7F5C1156  People are debating whether if drivers should ...   \n",
       "4      50B3435E475B  Texting and driving Over half of drivers in to...   \n",
       "...             ...                                                ...   \n",
       "15137  0814426B27DF  Most people ask more than one person for advic...   \n",
       "15138  8F4B595CF9E7  Do you ever want more opinions and options whe...   \n",
       "15139  6B5809C83978  Has anyone ever gave you advice? Was the advic...   \n",
       "15140  AFEC37C2D43F  There has been at least one point in everyone'...   \n",
       "15141  4C471936CD75  In ancient times, and also still today in some...   \n",
       "\n",
       "       token_length  kfold  \n",
       "0               442      0  \n",
       "1               242      0  \n",
       "2               364      0  \n",
       "3               671      0  \n",
       "4               420      0  \n",
       "...             ...    ...  \n",
       "15137           512      4  \n",
       "15138           639      4  \n",
       "15139           411      4  \n",
       "15140           647      4  \n",
       "15141          1166      4  \n",
       "\n",
       "[15142 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_pldata = pd.read_csv('/home/rashmi/Documents/kaggle/feedback3/input/fb3_fb1_merged/all_pldata.csv')\n",
    "all_pldata.columns = ['text_id','full_text','token_length','kfold']\n",
    "all_pldata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 130
    },
    "executionInfo": {
     "elapsed": 949,
     "status": "ok",
     "timestamp": 1663840897369,
     "user": {
      "displayName": "Rashmi Banthia",
      "userId": "08241869107709835428"
     },
     "user_tz": 240
    },
    "id": "4jAuFkMhDLQH",
    "outputId": "bcc4a704-935e-46fe-ec08-b0a82c0d1606"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3911, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>cohesion</th>\n",
       "      <th>syntax</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>phraseology</th>\n",
       "      <th>grammar</th>\n",
       "      <th>conventions</th>\n",
       "      <th>kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0016926B079C</td>\n",
       "      <td>I think that students would benefit from learn...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0022683E9EA5</td>\n",
       "      <td>When a problem is a change you have to let it ...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text_id                                          full_text  cohesion  \\\n",
       "0  0016926B079C  I think that students would benefit from learn...       3.5   \n",
       "1  0022683E9EA5  When a problem is a change you have to let it ...       2.5   \n",
       "\n",
       "   syntax  vocabulary  phraseology  grammar  conventions  kfold  \n",
       "0     3.5         3.0          3.0      4.0          3.0      1  \n",
       "1     2.5         3.0          2.0      2.0          2.5      0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_folds= pd.read_csv(CFG.TRAIN_FOLDS)\n",
    "# df_folds['full_text'] = df_folds.full_text.apply(lambda x : resolve_encodings_and_normalize(x))\n",
    "print(df_folds.shape)\n",
    "df_folds.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1663840897369,
     "user": {
      "displayName": "Rashmi Banthia",
      "userId": "08241869107709835428"
     },
     "user_tz": 240
    },
    "id": "khQRqQann0hW"
   },
   "outputs": [],
   "source": [
    "df_folds['full_text'] = df_folds.full_text.apply(lambda x: x.replace(\"\\n\\n\",\" [PARAGRAPH] \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1663840897370,
     "user": {
      "displayName": "Rashmi Banthia",
      "userId": "08241869107709835428"
     },
     "user_tz": 240
    },
    "id": "OndTNY7QKECu",
    "outputId": "9a3848a1-c9ac-46ea-ea9b-fd4934a358d3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1    783\n",
       " 0    782\n",
       " 4    782\n",
       " 3    782\n",
       " 2    782\n",
       " Name: kfold, dtype: int64,\n",
       " (3129, 9))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_folds.kfold.value_counts(), df_folds[df_folds.kfold!=0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1663840897370,
     "user": {
      "displayName": "Rashmi Banthia",
      "userId": "08241869107709835428"
     },
     "user_tz": 240
    },
    "id": "CYmJLL1yFKzo"
   },
   "outputs": [],
   "source": [
    "def _prepare_training_data_helper(df, is_train):\n",
    "      # print(df['full_text'])\n",
    "      tok = CFG.tokenizer.encode(df['full_text'].values[0], add_special_tokens=True, max_length=CFG.max_len)\n",
    "      label = df[true_cols].values[0]\n",
    "\n",
    "      return {'input_ids': tok, 'label': label, 'essay_id': df['text_id'].values[0] }\n",
    "\n",
    "\n",
    "\n",
    "def prepare_training_data(df, tokenizer, num_jobs, is_train):\n",
    "    \n",
    "    results = Parallel()(\n",
    "        delayed(_prepare_training_data_helper)(gdf, is_train) for gn, gdf in tqdm(df.groupby('text_id'))\n",
    "    )\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6568,
     "status": "ok",
     "timestamp": 1663840903928,
     "user": {
      "displayName": "Rashmi Banthia",
      "userId": "08241869107709835428"
     },
     "user_tz": 240
    },
    "id": "PJXsztLfHR9A",
    "outputId": "d56243cd-4879-4e92-c63a-74ef3a75b022"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3129 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "100%|██████████| 3129/3129 [00:02<00:00, 1302.85it/s]\n"
     ]
    }
   ],
   "source": [
    "folds = df_folds.copy()\n",
    "fold=0\n",
    "train_df = folds[folds[\"kfold\"] != fold].reset_index(drop=True)#.head(500)\n",
    "valid_df = folds[folds[\"kfold\"] == fold].reset_index(drop=True)\n",
    "NUM_JOBS = os.cpu_count()\n",
    "training_samples_ = prepare_training_data(train_df, CFG.tokenizer, num_jobs=NUM_JOBS, is_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1663840903929,
     "user": {
      "displayName": "Rashmi Banthia",
      "userId": "08241869107709835428"
     },
     "user_tz": 240
    },
    "id": "7xNvAxZhcxIE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1663840903929,
     "user": {
      "displayName": "Rashmi Banthia",
      "userId": "08241869107709835428"
     },
     "user_tz": 240
    },
    "id": "pJbzlfXeHSR6"
   },
   "outputs": [],
   "source": [
    "class FeedbackDataset:\n",
    "    def __init__(self, samples):\n",
    "        self.samples = samples\n",
    "        self.tokenizer = CFG.tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        ids = self.samples[idx][\"input_ids\"]\n",
    "        label = self.samples[idx][\"label\"]\n",
    "        essay_id = self.samples[idx][\"essay_id\"]\n",
    "        mask = [1] * len(ids)\n",
    "        # print(len(ids),len(mask),len(label))\n",
    "        return {\n",
    "            \"ids\": ids,\n",
    "            \"mask\": mask,\n",
    "            \"essay_id\":essay_id,\n",
    "            \"targets\": label,\n",
    "\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "class Collate:\n",
    "    def __init__(self, cfg):\n",
    "        self.tokenizer = cfg.tokenizer\n",
    "        self.cfg = cfg\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        output = dict()\n",
    "        output[\"ids\"] = [sample[\"ids\"] for sample in batch]\n",
    "        output[\"mask\"] = [sample[\"mask\"] for sample in batch]\n",
    "        output[\"essay_id\"] = [sample[\"essay_id\"] for sample in batch]\n",
    "        output[\"targets\"] = [sample[\"targets\"] for sample in batch]\n",
    "            \n",
    "        # calculate max token length of this batch\n",
    "        batch_max = max([len(ids) for ids in output[\"ids\"]])\n",
    "    \n",
    "        # add padding\n",
    "        if self.tokenizer.padding_side == \"right\":\n",
    "            output[\"ids\"] = [s + (batch_max - len(s)) * [self.tokenizer.pad_token_id] for s in output[\"ids\"]]\n",
    "            output[\"mask\"] = [s + (batch_max - len(s)) * [0] for s in output[\"mask\"]]\n",
    "        else:\n",
    "            output[\"ids\"] = [(batch_max - len(s)) * [self.tokenizer.pad_token_id] + s for s in output[\"ids\"]]\n",
    "            output[\"mask\"] = [(batch_max - len(s)) * [0] + s for s in output[\"mask\"]]\n",
    "        \n",
    "        # convert to tensors\n",
    "        output[\"ids\"] = torch.tensor(output[\"ids\"], dtype=torch.long)\n",
    "        output[\"mask\"] = torch.tensor(output[\"mask\"], dtype=torch.long)\n",
    "        output[\"targets\"] = torch.tensor(output[\"targets\"], dtype=torch.float)\n",
    "       \n",
    "        \n",
    "        # print(output['ids'].shape, output['mask'].shape, output['targets'].shape)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 7171,
     "status": "ok",
     "timestamp": 1663840911083,
     "user": {
      "displayName": "Rashmi Banthia",
      "userId": "08241869107709835428"
     },
     "user_tz": 240
    },
    "id": "LSsFyKAfCHSw"
   },
   "outputs": [],
   "source": [
    "train_dataset = FeedbackDataset(training_samples_)\n",
    "collate_fn = Collate(CFG)\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                              batch_size=CFG.batch_size,\n",
    "                              shuffle=True,  collate_fn=collate_fn, \n",
    "                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n",
    "for step, inputs in enumerate(train_loader):\n",
    "  # print(step)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedBackModel(nn.Module):\n",
    "    def __init__(self, model_name):\n",
    "        super().__init__()\n",
    "\n",
    "        hidden_dropout_prob: float = 0.0\n",
    "        self.model_config = AutoConfig.from_pretrained(model_name)\n",
    "\n",
    "        self.model_config.update(\n",
    "            {\n",
    "                \"output_hidden_states\": True,\n",
    "                \"hidden_dropout_prob\": hidden_dropout_prob,\n",
    "                \"add_pooling_layer\": False,\n",
    "                \"num_labels\": CFG.num_labels,\n",
    "                 \"attention_probs_dropout_prob\":0.0 \n",
    "            }\n",
    "        )\n",
    "\n",
    "        self.model = AutoModel.from_pretrained(model_name, config=self.model_config)\n",
    "        self.model.resize_token_embeddings(len(CFG.tokenizer))\n",
    "        self.output = nn.Linear(self.model_config.hidden_size, CFG.num_labels)\n",
    "\n",
    "\n",
    "    def forward(self, ids, mask, targets=None):\n",
    "        transformer_out = self.model(input_ids=ids, attention_mask=mask)\n",
    "\n",
    "        # Get CLS token for last 6 hidden layers\n",
    "        h1 = transformer_out[1][-1][:,0,:].reshape((-1, 1, self.model_config.hidden_size)) #last 1 hidden state # CLS token (4,1,1024)\n",
    "        h2 = transformer_out[1][-2][:,0,:].reshape((-1, 1, self.model_config.hidden_size)) #2nd last hidden state\n",
    "        h3 = transformer_out[1][-3][:,0,:].reshape((-1, 1, self.model_config.hidden_size))\n",
    "        h4 = transformer_out[1][-4][:,0,:].reshape((-1, 1, self.model_config.hidden_size))\n",
    "        h5 = transformer_out[1][-5][:,0,:].reshape((-1, 1, self.model_config.hidden_size))\n",
    "        h6 = transformer_out[1][-6][:,0,:].reshape((-1, 1, self.model_config.hidden_size))\n",
    "        h7 = transformer_out[1][-7][:,0,:].reshape((-1, 1, self.model_config.hidden_size))\n",
    "        h8 = transformer_out[1][-8][:,0,:].reshape((-1, 1, self.model_config.hidden_size))\n",
    "\n",
    "        all_h = torch.cat([ h1, h2, h3, h4, h5, h6,h7,h8], 1)\n",
    "        # Average CLS token for 6 hidden layers\n",
    "        all_h_mean = torch.mean(all_h,1).reshape((-1, 1, self.model_config.hidden_size)) # torch.Size([bs, 1, hidden size])\n",
    "\n",
    "        # Average CLS token for last hidden state + CLS token for 6 hidden layers \n",
    "        sequence_output = torch.mean(torch.cat([transformer_out.last_hidden_state[:,0,:].reshape((-1, 1, self.model_config.hidden_size)),\n",
    "                                                all_h_mean],1),1)\n",
    "\n",
    "        logits = self.output(sequence_output)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1663840911084,
     "user": {
      "displayName": "Rashmi Banthia",
      "userId": "08241869107709835428"
     },
     "user_tz": 240
    },
    "id": "hRPP7PKEH9jN"
   },
   "outputs": [],
   "source": [
    "# m = FeedBackModel(CFG.model)\n",
    "# m(inputs['ids'], inputs['mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1663840911084,
     "user": {
      "displayName": "Rashmi Banthia",
      "userId": "08241869107709835428"
     },
     "user_tz": 240
    },
    "id": "CocNAH_fRKER"
   },
   "outputs": [],
   "source": [
    "class Loss_Fn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lfn = nn.MSELoss()\n",
    "    \n",
    "    def forward(self, outputs, targets):\n",
    "        loss = self.lfn(outputs, targets)\n",
    "        return loss\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.features.features import config\n",
    "\n",
    "class AWP:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        optimizer,\n",
    "        adv_param = 'weight',\n",
    "        adv_lr = 1,\n",
    "        adv_eps = 0.2,\n",
    "        start_step = 0,\n",
    "        adv_step = 1,\n",
    "        scaler = None\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.adv_param = adv_param\n",
    "        self.adv_lr = adv_lr\n",
    "        self.adv_eps = adv_eps\n",
    "        self.start_step = start_step\n",
    "        self.adv_step = adv_step\n",
    "        self.backup = {}\n",
    "        self.backup_eps = {}\n",
    "        self.scaler = scaler\n",
    "\n",
    "    def attack_backward(self, batch, epoch):\n",
    "        \n",
    "        criterion = Loss_Fn()\n",
    "        \n",
    "        if (self.adv_lr == 0) or (epoch < self.start_step):\n",
    "            return None\n",
    "\n",
    "        self._save()\n",
    "        for i in range(self.adv_step):\n",
    "            self._attack_step() \n",
    "            with autocast(enabled = CFG.apex):\n",
    "                input_ids = batch['ids'].to(CFG.device)\n",
    "                attention_mask = batch['mask'].to(CFG.device)\n",
    "                # token_type_ids = batch['token_type_ids'].to(cfg.device)\n",
    "                labels = batch['targets'].to(CFG.device)\n",
    "                tr_logits = self.model(input_ids, attention_mask,  labels)\n",
    "                \n",
    "                loss = criterion(tr_logits, labels)\n",
    "                adv_loss = loss\n",
    "                if CFG.gradient_accumulation_steps > 1:\n",
    "                    adv_loss = loss / CFG.gradient_accumulation_steps\n",
    "                    \n",
    "#                 adv_loss = adv_loss.mean()\n",
    "            self.optimizer.zero_grad()\n",
    "            self.scaler.scale(adv_loss).backward()\n",
    "            \n",
    "        self._restore()\n",
    "\n",
    "    def _attack_step(self):\n",
    "        e = 1e-6\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad and param.grad is not None and self.adv_param in name:\n",
    "                norm1 = torch.norm(param.grad)\n",
    "                norm2 = torch.norm(param.data.detach())\n",
    "                if norm1 != 0 and not torch.isnan(norm1):\n",
    "                    r_at = self.adv_lr * param.grad / (norm1 + e) * (norm2 + e)\n",
    "                    param.data.add_(r_at)\n",
    "                    param.data = torch.min(\n",
    "                        torch.max(param.data, self.backup_eps[name][0]), self.backup_eps[name][1]\n",
    "                    )\n",
    "                    \n",
    "    def _save(self):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad and param.grad is not None and self.adv_param in name:\n",
    "                if name not in self.backup:\n",
    "                    self.backup[name] = param.data.clone()\n",
    "                    grad_eps = self.adv_eps * param.abs().detach()\n",
    "                    self.backup_eps[name] = (\n",
    "                        self.backup[name] - grad_eps,\n",
    "                        self.backup[name] + grad_eps,\n",
    "                    )\n",
    "\n",
    "    def _restore(self,):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if name in self.backup:\n",
    "                param.data = self.backup[name]\n",
    "        self.backup = {}\n",
    "        self.backup_eps = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1663840911084,
     "user": {
      "displayName": "Rashmi Banthia",
      "userId": "08241869107709835428"
     },
     "user_tz": 240
    },
    "id": "EFSCOAs_IErh"
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Helper functions\n",
    "# ====================================================\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "def get_score(outputs,targets): #outputs=preds, targets=groundtruth\n",
    "    mcrmse = []\n",
    "    for i in range(CFG.num_labels):\n",
    "        mcrmse.append(\n",
    "            metrics.mean_squared_error(\n",
    "                targets[:, i],\n",
    "                outputs[:, i],\n",
    "                squared=False,\n",
    "            ),\n",
    "        )\n",
    "    mcrmse = np.mean(mcrmse)\n",
    "    return mcrmse # {\"mcrmse\": torch.tensor(mcrmse, device=device)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1663840911085,
     "user": {
      "displayName": "Rashmi Banthia",
      "userId": "08241869107709835428"
     },
     "user_tz": 240
    },
    "id": "BFI3LtAcKIUj"
   },
   "outputs": [],
   "source": [
    "def train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device, valid_loader=None, valid_idx=None, best_score=np.inf):\n",
    "    model.train()\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n",
    "    losses = AverageMeter()\n",
    "    start = end = time.time()\n",
    "    global_step = 0\n",
    "    # best_score = np.inf\n",
    "\n",
    "\n",
    "    if CFG.use_awp:\n",
    "        # Initialize AWP\n",
    "        log_awp=True\n",
    "        awp = AWP(model, optimizer, adv_lr = CFG.adv_lr, adv_eps = CFG.adv_eps, start_step = CFG.start_awp_epoch, scaler = scaler)\n",
    "\n",
    "\n",
    "    for step, inputs in enumerate(train_loader):\n",
    "        model.train()\n",
    "        gc.collect()\n",
    "        # for k, v in inputs.items():\n",
    "        #     inputs[k] = v.to(device)\n",
    "        inputs['ids'] = inputs['ids'].to(device)\n",
    "        inputs['mask'] = inputs['mask'].to(device)\n",
    "\n",
    "        labels = inputs['targets'].to(device)\n",
    "        batch_size = labels.size(0)\n",
    "        with torch.cuda.amp.autocast(enabled=CFG.apex):\n",
    "            y_preds = model(inputs['ids'],inputs['mask'])\n",
    "            # print(y_preds.shape, labels.shape, labels.view(-1, 1).shape)\n",
    "            loss = criterion(y_preds, labels) #.view(-1, 1))\n",
    "            \n",
    "        if CFG.gradient_accumulation_steps > 1:\n",
    "            loss = loss / CFG.gradient_accumulation_steps\n",
    "        \n",
    "        \n",
    "        losses.update(loss.item(), batch_size)\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        if CFG.use_awp and best_score <= CFG.awp_score_check:\n",
    "            if best_score <= CFG.awp_score_check and log_awp:\n",
    "                LOGGER.info(' Start AWP '.center(50, '-'))\n",
    "                log_awp=False\n",
    "            if (step + 1) % CFG.gradient_accumulation_steps == 0:\n",
    "                awp.attack_backward(inputs, epoch)\n",
    "        \n",
    "\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n",
    "        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "            global_step += 1\n",
    "            if CFG.batch_scheduler:\n",
    "                scheduler.step()\n",
    "        end = time.time()\n",
    "        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n",
    "            print('Epoch: [{0}][{1}/{2}] '\n",
    "                  'Elapsed {remain:s} '\n",
    "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                  'Grad: {grad_norm:.4f}  '\n",
    "                  'LR: {lr:.8f}  '\n",
    "                  .format(epoch+1, step, len(train_loader), \n",
    "                          remain=timeSince(start, float(step+1)/len(train_loader)),\n",
    "                          loss=losses,\n",
    "                          grad_norm=grad_norm,\n",
    "                          lr=scheduler.get_lr()[0]))\n",
    "        if CFG.wandb:\n",
    "            wandb.log({f\"[fold{fold}] loss\": losses.val,\n",
    "                       f\"[fold{fold}] lr\": scheduler.get_lr()[0]})\n",
    "        \n",
    "        if CFG.val_strategy==\"batch\": \n",
    "            if step % CFG.val_steps == 0 or step == (len(train_loader)-1): # or if last step \n",
    "                  # Validate here\n",
    "                  avg_val_loss, predictions, output_map = valid_fn(valid_loader, model, criterion, device, valid_idx)\n",
    "                  \n",
    "                  valid_df = df_folds[df_folds.text_id.isin(valid_idx)].copy()\n",
    "                  for i,c in enumerate(true_cols):\n",
    "                      valid_df.loc[:, f'pred_{c}'] = valid_df['text_id'].apply(lambda x: output_map[x][i])\n",
    "                \n",
    "                  valid_labels = valid_df[true_cols].values\n",
    "                  valid_preds = valid_df[pred_cols].values\n",
    "\n",
    "                  score = get_score(valid_preds,valid_labels) \n",
    "                  save_preds = valid_df[pred_cols].values\n",
    "\n",
    "                  if  score < best_score:\n",
    "                      best_score = score\n",
    "                      LOGGER.info(f'Epoch {epoch+1} - Step {step}/{len(train_loader)} - Save Best Score: {best_score:.4f} Model')\n",
    "                      torch.save({'model': model.state_dict(),\n",
    "                                  'predictions': save_preds},\n",
    "                                  OUTPUT_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\")\n",
    "                      \n",
    "\n",
    "    return losses.avg, best_score\n",
    "\n",
    "\n",
    "\n",
    "def valid_fn(valid_loader, model, criterion, device, valid_idx):\n",
    "    losses = AverageMeter()\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    start = end = time.time()\n",
    "    for step, inputs in enumerate(valid_loader):\n",
    "        inputs['ids'] = inputs['ids'].to(device)\n",
    "        inputs['mask'] = inputs['mask'].to(device)\n",
    "\n",
    "        labels = inputs['targets'].to(device)\n",
    "        batch_size = labels.size(0)\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(inputs['ids'],inputs['mask'])\n",
    "            loss = criterion(y_preds, labels) #.view(-1, 1))\n",
    "            \n",
    "        if CFG.gradient_accumulation_steps > 1:\n",
    "            loss = loss / CFG.gradient_accumulation_steps\n",
    "        \n",
    "        losses.update(loss.item(), batch_size)\n",
    "        \n",
    "        preds.append(y_preds.detach().to('cpu').numpy())\n",
    "\n",
    "        end = time.time()\n",
    "        if step == (len(valid_loader)-1): #print only at the end \n",
    "            print('EVAL: [{0}/{1}] '\n",
    "                  'Elapsed {remain:s} '\n",
    "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                  .format(step, len(valid_loader),\n",
    "                          loss=losses,\n",
    "                          remain=timeSince(start, float(step+1)/len(valid_loader))))\n",
    "    \n",
    "    preds = np.vstack(preds) \n",
    "\n",
    "    output_map = {}\n",
    "    for x, y in zip(valid_idx, preds):\n",
    "        output_map[x] = y.tolist()\n",
    "    \n",
    "    return losses.avg, preds, output_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1663840911085,
     "user": {
      "displayName": "Rashmi Banthia",
      "userId": "08241869107709835428"
     },
     "user_tz": 240
    },
    "id": "c-mkKk9I0YE1"
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# train loop\n",
    "# ====================================================\n",
    "def train_loop(folds, fold):\n",
    "     \n",
    "    seed_everything(seed=CFG.seed)\n",
    "\n",
    "    LOGGER.info(f\"========== fold: {fold} training ==========\")\n",
    "\n",
    "    # ====================================================\n",
    "    # loader\n",
    "    # ====================================================\n",
    "    train_df = folds[folds[\"kfold\"] != fold].reset_index(drop=True)#.head(500)\n",
    "    valid_df = folds[folds[\"kfold\"] == fold].reset_index(drop=True)\n",
    "\n",
    "    pl_data_fold = pd.read_csv(f'/home/rashmi/Documents/kaggle/feedback3/input/fb3-psuedo-labels-1/exp_PL1_from_exp47_fold{fold}.csv')\n",
    "    pl_data_fold = pl_data_fold.merge(all_pldata[['text_id','kfold']],on='text_id',how='left')\n",
    "    pl_data_fold = pl_data_fold[train_df.columns]\n",
    "    train_df = pd.concat([train_df,pl_data_fold[pl_data_fold.kfold==fold]])\n",
    "\n",
    "    NUM_JOBS = os.cpu_count()\n",
    "    # training_samples_ = prepare_training_data(train_df, CFG.tokenizer, num_jobs=NUM_JOBS, is_train=True)\n",
    "    # valid_samples_ = prepare_training_data(valid_df, CFG.tokenizer, num_jobs=NUM_JOBS, is_train=True)\n",
    "\n",
    "    # training_samples, valid_samples = training_samples_, valid_samples_\n",
    "\n",
    "    # valid_idx = []\n",
    "    # for x in valid_samples:\n",
    "    #     valid_idx.append(x['essay_id'])  \n",
    "    \n",
    "    # print(len(valid_idx), valid_df.shape)\n",
    "\n",
    "    # train_dataset = FeedbackDataset(training_samples)\n",
    "    # valid_dataset = FeedbackDataset(valid_samples)\n",
    "\n",
    "    # collate_fn = Collate(CFG)\n",
    "\n",
    "    # train_loader = DataLoader(train_dataset,\n",
    "    #                           batch_size=CFG.batch_size,\n",
    "    #                           shuffle=True,  collate_fn=collate_fn, \n",
    "    #                           num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n",
    "    # valid_loader = DataLoader(valid_dataset,\n",
    "    #                           batch_size=CFG.batch_size,\n",
    "    #                           shuffle=False, collate_fn=collate_fn, \n",
    "    #                           num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n",
    "    # ====================================================\n",
    "    # model & optimizer\n",
    "    # ====================================================\n",
    "    model = FeedBackModel(CFG.model) \n",
    "    torch.save(model.model_config, OUTPUT_DIR+'config.pth')\n",
    "    model.to(device)\n",
    "\n",
    "    if CFG.wandb: # this logs all gradients\n",
    "        wandb.watch(model, log='all')\n",
    "    \n",
    "    def get_optimizer_params(model, encoder_lr, decoder_lr, weight_decay=0.0):\n",
    "        param_optimizer = list(model.named_parameters())\n",
    "        no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "        optimizer_parameters = [\n",
    "            {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "              'lr': encoder_lr, 'weight_decay': weight_decay},\n",
    "            {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "              'lr': encoder_lr, 'weight_decay': 0.0},\n",
    "            {'params': [p for n, p in model.named_parameters() if \"model\" not in n],\n",
    "              'lr': decoder_lr, 'weight_decay': 0.0}\n",
    "        ]\n",
    "        return optimizer_parameters\n",
    "\n",
    "    optimizer_parameters = get_optimizer_params(model,\n",
    "                                                encoder_lr=CFG.encoder_lr, \n",
    "                                                decoder_lr=CFG.decoder_lr,\n",
    "                                                weight_decay=CFG.weight_decay)\n",
    "    \n",
    "    if CFG.gpu_optimize_config_adam:\n",
    "        optimizer = bnb.optim.AdamW(optimizer_parameters, lr=CFG.encoder_lr, optim_bits=8)\n",
    "    else:\n",
    "        optimizer = AdamW(optimizer_parameters, lr=CFG.encoder_lr, eps=CFG.eps, betas=CFG.betas)\n",
    "    \n",
    "    # ====================================================\n",
    "    # scheduler\n",
    "    # ====================================================\n",
    "    def get_scheduler(cfg, optimizer, num_train_steps):\n",
    "        if cfg.scheduler == 'linear':\n",
    "            scheduler = get_linear_schedule_with_warmup(\n",
    "                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps\n",
    "            )\n",
    "        elif cfg.scheduler == 'cosine':\n",
    "            scheduler = get_cosine_schedule_with_warmup(\n",
    "                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps, num_cycles=cfg.num_cycles\n",
    "            )\n",
    "        return scheduler\n",
    "    \n",
    "    num_train_steps = int(len(train_df) / CFG.batch_size * CFG.epochs)\n",
    "    scheduler = get_scheduler(CFG, optimizer, num_train_steps)\n",
    "\n",
    "    # ====================================================\n",
    "    # loop\n",
    "    # ====================================================\n",
    "    # criterion = nn.BCEWithLogitsLoss(reduction=\"mean\")\n",
    "    # criterion = nn.CrossEntropyLoss()\n",
    "    criterion = Loss_Fn() #MSECorrLoss()\n",
    "    \n",
    "    best_score = np.inf\n",
    "\n",
    "    for epoch in range(CFG.epochs):\n",
    "        if epoch==0:\n",
    "            CFG.max_len = 768\n",
    "        if epoch==1:\n",
    "            CFG.max_len = 512\n",
    "        if epoch==2:\n",
    "            CFG.max_len = 512 \n",
    "        else:\n",
    "            CFG.max_len = 470\n",
    "            \n",
    "        training_samples_ = prepare_training_data(train_df, CFG.tokenizer, num_jobs=NUM_JOBS, is_train=True)\n",
    "        valid_samples_ = prepare_training_data(valid_df, CFG.tokenizer, num_jobs=NUM_JOBS, is_train=True)\n",
    "\n",
    "        training_samples, valid_samples = training_samples_, valid_samples_\n",
    "\n",
    "        valid_idx = []\n",
    "        for x in valid_samples:\n",
    "            valid_idx.append(x['essay_id'])  \n",
    "\n",
    "        print(len(valid_idx), valid_df.shape)\n",
    "\n",
    "        train_dataset = FeedbackDataset(training_samples)\n",
    "        valid_dataset = FeedbackDataset(valid_samples)\n",
    "\n",
    "        collate_fn = Collate(CFG)\n",
    "\n",
    "        train_loader = DataLoader(train_dataset,\n",
    "                                  batch_size=CFG.batch_size,\n",
    "                                  shuffle=True,  collate_fn=collate_fn, \n",
    "                                  num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n",
    "        valid_loader = DataLoader(valid_dataset,\n",
    "                                  batch_size=CFG.batch_size,\n",
    "                                  shuffle=False, collate_fn=collate_fn, \n",
    "                                  num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n",
    "        \n",
    "        start_time = time.time()\n",
    "\n",
    "        # train and validate\n",
    "        avg_loss, best_score = train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device, valid_loader, valid_idx, best_score)\n",
    "\n",
    "\n",
    "    predictions = torch.load(OUTPUT_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\", \n",
    "                             map_location=torch.device('cpu'))['predictions']\n",
    "    \n",
    "    valid_df['pred_cohesion'] = predictions[:,0]\n",
    "    valid_df['pred_syntax'] = predictions[:,1]\n",
    "    valid_df['pred_vocabulary'] = predictions[:,2]\n",
    "  \n",
    "    valid_df['pred_phraseology'] = predictions[:,3]\n",
    "    valid_df['pred_grammar'] = predictions[:,4]\n",
    "    valid_df['pred_conventions'] = predictions[:,5]\n",
    "    \n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    return valid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 0 training ==========\n",
      "Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['mask_predictions.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.classifier.bias']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 6158/6158 [00:05<00:00, 1207.50it/s]\n",
      "100%|██████████| 782/782 [00:00<00:00, 1298.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782 (782, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/1539] Elapsed 0m 1s (remain 43m 4s) Loss: 8.8496(8.8496) Grad: inf  LR: 0.00000010  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Step 0/1539 - Save Best Score: 2.9045 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [195/196] Elapsed 0m 23s (remain 0m 0s) Loss: 10.1507(8.5389) \n",
      "Epoch: [1][100/1539] Elapsed 1m 5s (remain 15m 26s) Loss: 0.3086(7.9381) Grad: 57168.4961  LR: 0.00001000  \n",
      "Epoch: [1][200/1539] Elapsed 1m 42s (remain 11m 24s) Loss: 0.1747(4.1039) Grad: 18277.2246  LR: 0.00000999  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Step 250/1539 - Save Best Score: 0.4611 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [195/196] Elapsed 0m 23s (remain 0m 0s) Loss: 0.2408(0.2132) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "------------------- Start AWP --------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][300/1539] Elapsed 2m 45s (remain 11m 21s) Loss: 0.0678(2.7882) Grad: 13427.2432  LR: 0.00000997  \n",
      "Epoch: [1][400/1539] Elapsed 3m 23s (remain 9m 37s) Loss: 0.2282(2.1275) Grad: 37235.1992  LR: 0.00000994  \n",
      "Epoch: [1][500/1539] Elapsed 4m 1s (remain 8m 19s) Loss: 0.3853(1.7335) Grad: 42104.2148  LR: 0.00000989  \n",
      "EVAL: [195/196] Elapsed 0m 24s (remain 0m 0s) Loss: 0.1537(0.2214) \n",
      "Epoch: [1][600/1539] Elapsed 5m 3s (remain 7m 54s) Loss: 0.2136(1.4672) Grad: 14389.0195  LR: 0.00000983  \n",
      "Epoch: [1][700/1539] Elapsed 5m 41s (remain 6m 48s) Loss: 0.0457(1.2772) Grad: 10852.8164  LR: 0.00000976  \n",
      "EVAL: [195/196] Elapsed 0m 23s (remain 0m 0s) Loss: 0.3294(0.2155) \n",
      "Epoch: [1][800/1539] Elapsed 6m 42s (remain 6m 10s) Loss: 0.0835(1.1322) Grad: 11563.7900  LR: 0.00000967  \n",
      "Epoch: [1][900/1539] Elapsed 7m 19s (remain 5m 11s) Loss: 0.1053(1.0211) Grad: 15626.3145  LR: 0.00000957  \n",
      "Epoch: [1][1000/1539] Elapsed 7m 57s (remain 4m 16s) Loss: 0.1740(0.9302) Grad: 17356.0176  LR: 0.00000946  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Step 1000/1539 - Save Best Score: 0.4527 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [195/196] Elapsed 0m 23s (remain 0m 0s) Loss: 0.2769(0.2055) \n",
      "Epoch: [1][1100/1539] Elapsed 9m 1s (remain 3m 35s) Loss: 0.1519(0.8558) Grad: 23906.2793  LR: 0.00000934  \n",
      "Epoch: [1][1200/1539] Elapsed 9m 38s (remain 2m 42s) Loss: 0.1297(0.7948) Grad: 29812.9180  LR: 0.00000921  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Step 1250/1539 - Save Best Score: 0.4511 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [195/196] Elapsed 0m 23s (remain 0m 0s) Loss: 0.2071(0.2038) \n",
      "Epoch: [1][1300/1539] Elapsed 10m 42s (remain 1m 57s) Loss: 0.0747(0.7420) Grad: 19107.8828  LR: 0.00000906  \n",
      "Epoch: [1][1400/1539] Elapsed 11m 21s (remain 1m 7s) Loss: 0.0718(0.6980) Grad: 6552.0317  LR: 0.00000890  \n",
      "Epoch: [1][1500/1539] Elapsed 11m 59s (remain 0m 18s) Loss: 0.0630(0.6598) Grad: 8248.6934  LR: 0.00000874  \n",
      "EVAL: [195/196] Elapsed 0m 23s (remain 0m 0s) Loss: 0.3329(0.2216) \n",
      "Epoch: [1][1538/1539] Elapsed 12m 37s (remain 0m 0s) Loss: 0.1513(0.6463) Grad: 14301.7979  LR: 0.00000867  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Step 1538/1539 - Save Best Score: 0.4486 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [195/196] Elapsed 0m 24s (remain 0m 0s) Loss: 0.2339(0.2016) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6158/6158 [00:05<00:00, 1159.80it/s]\n",
      "100%|██████████| 782/782 [00:00<00:00, 1295.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782 (782, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "------------------- Start AWP --------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][0/1539] Elapsed 0m 1s (remain 34m 47s) Loss: 0.0841(0.0841) Grad: 180910.6250  LR: 0.00000867  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Step 0/1539 - Save Best Score: 0.4472 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [195/196] Elapsed 0m 23s (remain 0m 0s) Loss: 0.2192(0.2004) \n",
      "Epoch: [2][100/1539] Elapsed 1m 30s (remain 21m 32s) Loss: 0.1033(0.1011) Grad: 104010.2031  LR: 0.00000849  \n",
      "Epoch: [2][200/1539] Elapsed 2m 31s (remain 16m 46s) Loss: 0.1577(0.0988) Grad: 230135.3906  LR: 0.00000830  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Step 250/1539 - Save Best Score: 0.4444 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [195/196] Elapsed 0m 22s (remain 0m 0s) Loss: 0.2490(0.1980) \n",
      "Epoch: [2][300/1539] Elapsed 3m 55s (remain 16m 8s) Loss: 0.0576(0.0932) Grad: 114803.9219  LR: 0.00000810  \n",
      "Epoch: [2][400/1539] Elapsed 4m 55s (remain 13m 59s) Loss: 0.0933(0.0915) Grad: 123093.8203  LR: 0.00000789  \n",
      "Epoch: [2][500/1539] Elapsed 5m 54s (remain 12m 14s) Loss: 0.1062(0.0906) Grad: 217553.6562  LR: 0.00000768  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Step 500/1539 - Save Best Score: 0.4433 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [195/196] Elapsed 0m 21s (remain 0m 0s) Loss: 0.2343(0.1969) \n",
      "Epoch: [2][600/1539] Elapsed 7m 18s (remain 11m 24s) Loss: 0.0553(0.0896) Grad: 104256.1953  LR: 0.00000745  \n",
      "Epoch: [2][700/1539] Elapsed 8m 18s (remain 9m 55s) Loss: 0.0286(0.0890) Grad: 142210.8438  LR: 0.00000722  \n",
      "EVAL: [195/196] Elapsed 0m 21s (remain 0m 0s) Loss: 0.2684(0.2010) \n",
      "Epoch: [2][800/1539] Elapsed 9m 38s (remain 8m 53s) Loss: 0.0669(0.0890) Grad: 172894.3281  LR: 0.00000699  \n",
      "Epoch: [2][900/1539] Elapsed 10m 37s (remain 7m 31s) Loss: 0.0158(0.0886) Grad: 40591.3789  LR: 0.00000675  \n",
      "Epoch: [2][1000/1539] Elapsed 11m 36s (remain 6m 14s) Loss: 0.1208(0.0886) Grad: 161750.7656  LR: 0.00000650  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Step 1000/1539 - Save Best Score: 0.4432 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [195/196] Elapsed 0m 22s (remain 0m 0s) Loss: 0.2372(0.1969) \n",
      "Epoch: [2][1100/1539] Elapsed 13m 0s (remain 5m 10s) Loss: 0.0297(0.0883) Grad: 64693.7070  LR: 0.00000625  \n",
      "Epoch: [2][1200/1539] Elapsed 13m 59s (remain 3m 56s) Loss: 0.0225(0.0886) Grad: 72936.6172  LR: 0.00000600  \n",
      "EVAL: [195/196] Elapsed 0m 21s (remain 0m 0s) Loss: 0.2287(0.1978) \n",
      "Epoch: [2][1300/1539] Elapsed 15m 20s (remain 2m 48s) Loss: 0.0913(0.0888) Grad: 172778.8438  LR: 0.00000575  \n",
      "Epoch: [2][1400/1539] Elapsed 16m 20s (remain 1m 36s) Loss: 0.0702(0.0884) Grad: 127212.8750  LR: 0.00000549  \n",
      "Epoch: [2][1500/1539] Elapsed 17m 19s (remain 0m 26s) Loss: 0.0787(0.0885) Grad: 170000.8438  LR: 0.00000523  \n",
      "EVAL: [195/196] Elapsed 0m 21s (remain 0m 0s) Loss: 0.2904(0.1997) \n",
      "Epoch: [2][1538/1539] Elapsed 18m 4s (remain 0m 0s) Loss: 0.0298(0.0886) Grad: 87676.4609  LR: 0.00000513  \n",
      "EVAL: [195/196] Elapsed 0m 21s (remain 0m 0s) Loss: 0.2687(0.1977) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6158/6158 [00:05<00:00, 1203.83it/s]\n",
      "100%|██████████| 782/782 [00:00<00:00, 1302.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782 (782, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "------------------- Start AWP --------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][0/1539] Elapsed 0m 1s (remain 34m 52s) Loss: 0.0280(0.0280) Grad: 154193.5625  LR: 0.00000513  \n",
      "EVAL: [195/196] Elapsed 0m 24s (remain 0m 0s) Loss: 0.2714(0.1979) \n",
      "Epoch: [3][100/1539] Elapsed 1m 28s (remain 21m 1s) Loss: 0.0735(0.0797) Grad: 134058.5469  LR: 0.00000487  \n",
      "Epoch: [3][200/1539] Elapsed 2m 30s (remain 16m 39s) Loss: 0.0832(0.0820) Grad: 120968.8125  LR: 0.00000461  \n",
      "EVAL: [195/196] Elapsed 0m 24s (remain 0m 0s) Loss: 0.2903(0.1989) \n",
      "Epoch: [3][300/1539] Elapsed 3m 56s (remain 16m 11s) Loss: 0.0920(0.0849) Grad: 182717.3594  LR: 0.00000435  \n",
      "Epoch: [3][400/1539] Elapsed 4m 58s (remain 14m 7s) Loss: 0.0171(0.0863) Grad: 67799.5859  LR: 0.00000410  \n",
      "Epoch: [3][500/1539] Elapsed 6m 2s (remain 12m 30s) Loss: 0.0309(0.0838) Grad: 88767.2266  LR: 0.00000384  \n",
      "EVAL: [195/196] Elapsed 0m 24s (remain 0m 0s) Loss: 0.2877(0.1980) \n",
      "Epoch: [3][600/1539] Elapsed 7m 29s (remain 11m 41s) Loss: 0.1096(0.0840) Grad: 141939.7656  LR: 0.00000359  \n",
      "Epoch: [3][700/1539] Elapsed 8m 31s (remain 10m 12s) Loss: 0.0665(0.0846) Grad: 125589.2188  LR: 0.00000335  \n",
      "EVAL: [195/196] Elapsed 0m 25s (remain 0m 0s) Loss: 0.3130(0.2015) \n",
      "Epoch: [3][800/1539] Elapsed 10m 0s (remain 9m 13s) Loss: 0.1374(0.0838) Grad: 149938.5625  LR: 0.00000310  \n",
      "Epoch: [3][900/1539] Elapsed 11m 2s (remain 7m 49s) Loss: 0.0507(0.0842) Grad: 118566.7656  LR: 0.00000287  \n",
      "Epoch: [3][1000/1539] Elapsed 12m 5s (remain 6m 29s) Loss: 0.1286(0.0838) Grad: 132013.7344  LR: 0.00000264  \n",
      "EVAL: [195/196] Elapsed 0m 24s (remain 0m 0s) Loss: 0.3127(0.2031) \n",
      "Epoch: [3][1100/1539] Elapsed 13m 32s (remain 5m 23s) Loss: 0.0400(0.0828) Grad: 135826.9219  LR: 0.00000241  \n",
      "Epoch: [3][1200/1539] Elapsed 14m 35s (remain 4m 6s) Loss: 0.0071(0.0821) Grad: 34647.2070  LR: 0.00000219  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Step 1250/1539 - Save Best Score: 0.4429 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [195/196] Elapsed 0m 24s (remain 0m 0s) Loss: 0.2686(0.1967) \n",
      "Epoch: [3][1300/1539] Elapsed 16m 4s (remain 2m 56s) Loss: 0.1125(0.0817) Grad: 135844.1406  LR: 0.00000198  \n",
      "Epoch: [3][1400/1539] Elapsed 17m 7s (remain 1m 41s) Loss: 0.2327(0.0825) Grad: 133709.1562  LR: 0.00000178  \n",
      "Epoch: [3][1500/1539] Elapsed 18m 9s (remain 0m 27s) Loss: 0.1201(0.0825) Grad: 121151.6562  LR: 0.00000158  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Step 1500/1539 - Save Best Score: 0.4423 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [195/196] Elapsed 0m 26s (remain 0m 0s) Loss: 0.2629(0.1962) \n",
      "Epoch: [3][1538/1539] Elapsed 19m 1s (remain 0m 0s) Loss: 0.0215(0.0822) Grad: 81386.6172  LR: 0.00000151  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Step 1538/1539 - Save Best Score: 0.4423 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [195/196] Elapsed 0m 24s (remain 0m 0s) Loss: 0.2717(0.1961) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6158/6158 [00:05<00:00, 1188.00it/s]\n",
      "100%|██████████| 782/782 [00:00<00:00, 1287.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782 (782, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------- Start AWP --------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][0/1539] Elapsed 0m 1s (remain 33m 12s) Loss: 0.1543(0.1543) Grad: inf  LR: 0.00000151  \n",
      "EVAL: [195/196] Elapsed 0m 21s (remain 0m 0s) Loss: 0.2700(0.1963) \n",
      "Epoch: [4][100/1539] Elapsed 1m 23s (remain 19m 49s) Loss: 0.0749(0.0787) Grad: 118536.9609  LR: 0.00000133  \n",
      "Epoch: [4][200/1539] Elapsed 2m 23s (remain 15m 54s) Loss: 0.0516(0.0771) Grad: 72452.5312  LR: 0.00000116  \n",
      "EVAL: [195/196] Elapsed 0m 21s (remain 0m 0s) Loss: 0.2682(0.1970) \n",
      "Epoch: [4][300/1539] Elapsed 3m 46s (remain 15m 32s) Loss: 0.1660(0.0742) Grad: 185340.5938  LR: 0.00000100  \n",
      "Epoch: [4][400/1539] Elapsed 4m 46s (remain 13m 34s) Loss: 0.0930(0.0759) Grad: 125548.1797  LR: 0.00000085  \n",
      "Epoch: [4][500/1539] Elapsed 5m 47s (remain 11m 59s) Loss: 0.0340(0.0766) Grad: 83057.1484  LR: 0.00000071  \n",
      "EVAL: [195/196] Elapsed 0m 21s (remain 0m 0s) Loss: 0.3020(0.1998) \n",
      "Epoch: [4][600/1539] Elapsed 7m 9s (remain 11m 10s) Loss: 0.0805(0.0768) Grad: 148445.0000  LR: 0.00000058  \n",
      "Epoch: [4][700/1539] Elapsed 8m 8s (remain 9m 44s) Loss: 0.0984(0.0763) Grad: 98081.1719  LR: 0.00000047  \n",
      "EVAL: [195/196] Elapsed 0m 21s (remain 0m 0s) Loss: 0.2608(0.1966) \n",
      "Epoch: [4][800/1539] Elapsed 9m 29s (remain 8m 44s) Loss: 0.0189(0.0762) Grad: 69692.0703  LR: 0.00000036  \n",
      "Epoch: [4][900/1539] Elapsed 10m 28s (remain 7m 25s) Loss: 0.0382(0.0762) Grad: 98776.5703  LR: 0.00000027  \n",
      "Epoch: [4][1000/1539] Elapsed 11m 28s (remain 6m 10s) Loss: 0.1239(0.0766) Grad: 113244.1953  LR: 0.00000019  \n",
      "EVAL: [195/196] Elapsed 0m 21s (remain 0m 0s) Loss: 0.2929(0.1986) \n",
      "Epoch: [4][1100/1539] Elapsed 12m 50s (remain 5m 6s) Loss: 0.0036(0.0765) Grad: 36170.8242  LR: 0.00000013  \n",
      "Epoch: [4][1200/1539] Elapsed 13m 49s (remain 3m 53s) Loss: 0.0258(0.0766) Grad: 92901.3750  LR: 0.00000008  \n",
      "EVAL: [195/196] Elapsed 0m 22s (remain 0m 0s) Loss: 0.2805(0.1972) \n",
      "Epoch: [4][1300/1539] Elapsed 15m 12s (remain 2m 46s) Loss: 0.1975(0.0764) Grad: 159056.7344  LR: 0.00000004  \n",
      "Epoch: [4][1400/1539] Elapsed 16m 12s (remain 1m 35s) Loss: 0.1095(0.0764) Grad: 164754.2188  LR: 0.00000001  \n",
      "Epoch: [4][1500/1539] Elapsed 17m 12s (remain 0m 26s) Loss: 0.0759(0.0765) Grad: 140298.7344  LR: 0.00000000  \n",
      "EVAL: [195/196] Elapsed 0m 21s (remain 0m 0s) Loss: 0.2818(0.1973) \n",
      "Epoch: [4][1538/1539] Elapsed 17m 57s (remain 0m 0s) Loss: 0.0694(0.0763) Grad: 80554.4609  LR: 0.00000000  \n",
      "EVAL: [195/196] Elapsed 0m 22s (remain 0m 0s) Loss: 0.2818(0.1973) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 0 result ==========\n",
      "Score: 0.4423\n",
      "========== fold: 1 training ==========\n",
      "Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['mask_predictions.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.classifier.bias']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 6157/6157 [00:05<00:00, 1165.69it/s]\n",
      "100%|██████████| 783/783 [00:00<00:00, 1235.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "783 (783, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/1539] Elapsed 0m 1s (remain 26m 49s) Loss: 10.6121(10.6121) Grad: inf  LR: 0.00000010  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Step 0/1539 - Save Best Score: 2.9460 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [195/196] Elapsed 0m 21s (remain 0m 0s) Loss: 9.0841(8.7851) \n",
      "Epoch: [1][100/1539] Elapsed 1m 0s (remain 14m 25s) Loss: 0.6579(8.1450) Grad: 48127.2930  LR: 0.00001000  \n",
      "Epoch: [1][200/1539] Elapsed 1m 37s (remain 10m 45s) Loss: 0.0601(4.2382) Grad: 9421.9043  LR: 0.00000999  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Step 250/1539 - Save Best Score: 0.5038 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [195/196] Elapsed 0m 21s (remain 0m 0s) Loss: 0.2153(0.2578) \n",
      "Epoch: [1][300/1539] Elapsed 2m 36s (remain 10m 45s) Loss: 0.1441(2.8816) Grad: 9255.7275  LR: 0.00000997  \n",
      "Epoch: [1][400/1539] Elapsed 3m 12s (remain 9m 6s) Loss: 0.1353(2.2041) Grad: 13474.5361  LR: 0.00000994  \n",
      "Epoch: [1][500/1539] Elapsed 3m 48s (remain 7m 52s) Loss: 0.0439(1.7935) Grad: 6340.6787  LR: 0.00000989  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Step 500/1539 - Save Best Score: 0.4677 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [195/196] Elapsed 0m 22s (remain 0m 0s) Loss: 0.2354(0.2193) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "------------------- Start AWP --------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][600/1539] Elapsed 4m 48s (remain 7m 30s) Loss: 0.0286(1.5171) Grad: 5560.8086  LR: 0.00000983  \n",
      "Epoch: [1][700/1539] Elapsed 5m 24s (remain 6m 27s) Loss: 0.1669(1.3194) Grad: 11775.3760  LR: 0.00000976  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Step 750/1539 - Save Best Score: 0.4658 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [195/196] Elapsed 0m 21s (remain 0m 0s) Loss: 0.2461(0.2175) \n",
      "Epoch: [1][800/1539] Elapsed 6m 23s (remain 5m 53s) Loss: 0.0427(1.1722) Grad: 5549.7832  LR: 0.00000967  \n",
      "Epoch: [1][900/1539] Elapsed 6m 59s (remain 4m 56s) Loss: 0.7284(1.0572) Grad: 22687.5625  LR: 0.00000957  \n",
      "Epoch: [1][1000/1539] Elapsed 7m 35s (remain 4m 4s) Loss: 0.1215(0.9652) Grad: 9848.5889  LR: 0.00000946  \n",
      "EVAL: [195/196] Elapsed 0m 21s (remain 0m 0s) Loss: 0.2153(0.2215) \n",
      "Epoch: [1][1100/1539] Elapsed 8m 33s (remain 3m 24s) Loss: 0.1488(0.8877) Grad: 7247.4688  LR: 0.00000934  \n",
      "Epoch: [1][1200/1539] Elapsed 9m 8s (remain 2m 34s) Loss: 0.0875(0.8239) Grad: 4520.3887  LR: 0.00000921  \n",
      "EVAL: [195/196] Elapsed 0m 21s (remain 0m 0s) Loss: 0.2568(0.2261) \n",
      "Epoch: [1][1300/1539] Elapsed 10m 6s (remain 1m 50s) Loss: 0.0224(0.7723) Grad: 5179.2344  LR: 0.00000906  \n",
      "Epoch: [1][1400/1539] Elapsed 10m 41s (remain 1m 3s) Loss: 0.1232(0.7249) Grad: 8524.2070  LR: 0.00000890  \n",
      "Epoch: [1][1500/1539] Elapsed 11m 17s (remain 0m 17s) Loss: 0.1515(0.6857) Grad: 9275.2666  LR: 0.00000874  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Step 1500/1539 - Save Best Score: 0.4575 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [195/196] Elapsed 0m 21s (remain 0m 0s) Loss: 0.2341(0.2098) \n",
      "Epoch: [1][1538/1539] Elapsed 11m 55s (remain 0m 0s) Loss: 0.1614(0.6716) Grad: 5879.0947  LR: 0.00000867  \n",
      "EVAL: [195/196] Elapsed 0m 22s (remain 0m 0s) Loss: 0.2250(0.2100) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6157/6157 [00:05<00:00, 1227.13it/s]\n",
      "100%|██████████| 783/783 [00:00<00:00, 1312.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "783 (783, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "------------------- Start AWP --------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][0/1539] Elapsed 0m 1s (remain 34m 44s) Loss: 0.0285(0.0285) Grad: 227089.0625  LR: 0.00000867  \n",
      "EVAL: [195/196] Elapsed 0m 21s (remain 0m 0s) Loss: 0.2300(0.2110) \n",
      "Epoch: [2][100/1539] Elapsed 1m 23s (remain 19m 50s) Loss: 0.0782(0.0910) Grad: 125796.3828  LR: 0.00000849  \n",
      "Epoch: [2][200/1539] Elapsed 2m 23s (remain 15m 56s) Loss: 0.0949(0.0923) Grad: 146102.9531  LR: 0.00000830  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Step 250/1539 - Save Best Score: 0.4502 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [195/196] Elapsed 0m 22s (remain 0m 0s) Loss: 0.2515(0.2032) \n",
      "Epoch: [2][300/1539] Elapsed 3m 48s (remain 15m 40s) Loss: 0.0052(0.0895) Grad: 35120.5938  LR: 0.00000810  \n",
      "Epoch: [2][400/1539] Elapsed 4m 49s (remain 13m 40s) Loss: 0.1181(0.0897) Grad: 193459.1406  LR: 0.00000789  \n",
      "Epoch: [2][500/1539] Elapsed 5m 49s (remain 12m 3s) Loss: 0.0753(0.0909) Grad: 140054.3750  LR: 0.00000768  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Step 500/1539 - Save Best Score: 0.4497 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [195/196] Elapsed 0m 21s (remain 0m 0s) Loss: 0.2384(0.2027) \n",
      "Epoch: [2][600/1539] Elapsed 7m 12s (remain 11m 15s) Loss: 0.2399(0.0900) Grad: 120523.7891  LR: 0.00000745  \n",
      "Epoch: [2][700/1539] Elapsed 8m 13s (remain 9m 50s) Loss: 0.0620(0.0895) Grad: 123571.9844  LR: 0.00000722  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Step 750/1539 - Save Best Score: 0.4495 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [195/196] Elapsed 0m 21s (remain 0m 0s) Loss: 0.2450(0.2025) \n",
      "Epoch: [2][800/1539] Elapsed 9m 38s (remain 8m 52s) Loss: 0.0399(0.0934) Grad: 102663.0859  LR: 0.00000699  \n",
      "Epoch: [2][900/1539] Elapsed 10m 38s (remain 7m 31s) Loss: 0.0440(0.0918) Grad: 87042.3125  LR: 0.00000675  \n",
      "Epoch: [2][1000/1539] Elapsed 11m 38s (remain 6m 15s) Loss: 0.0737(0.0921) Grad: 80668.3594  LR: 0.00000650  \n",
      "EVAL: [195/196] Elapsed 0m 22s (remain 0m 0s) Loss: 0.2282(0.2081) \n",
      "Epoch: [2][1100/1539] Elapsed 13m 1s (remain 5m 10s) Loss: 0.1183(0.0915) Grad: 88270.9453  LR: 0.00000625  \n",
      "Epoch: [2][1200/1539] Elapsed 14m 1s (remain 3m 56s) Loss: 0.0497(0.0911) Grad: 70273.0625  LR: 0.00000600  \n",
      "EVAL: [195/196] Elapsed 0m 21s (remain 0m 0s) Loss: 0.2709(0.2040) \n",
      "Epoch: [2][1300/1539] Elapsed 15m 22s (remain 2m 48s) Loss: 0.0830(0.0909) Grad: 76964.3438  LR: 0.00000575  \n",
      "Epoch: [2][1400/1539] Elapsed 16m 24s (remain 1m 36s) Loss: 0.0578(0.0911) Grad: 43238.1758  LR: 0.00000549  \n",
      "Epoch: [2][1500/1539] Elapsed 17m 24s (remain 0m 26s) Loss: 0.1294(0.0913) Grad: 45367.2383  LR: 0.00000523  \n",
      "EVAL: [195/196] Elapsed 0m 21s (remain 0m 0s) Loss: 0.2675(0.2076) \n",
      "Epoch: [2][1538/1539] Elapsed 18m 9s (remain 0m 0s) Loss: 0.0554(0.0911) Grad: 40977.5586  LR: 0.00000513  \n",
      "EVAL: [195/196] Elapsed 0m 21s (remain 0m 0s) Loss: 0.2429(0.2027) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6157/6157 [00:05<00:00, 1198.37it/s]\n",
      "100%|██████████| 783/783 [00:00<00:00, 1301.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "783 (783, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "------------------- Start AWP --------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][0/1539] Elapsed 0m 1s (remain 35m 38s) Loss: 0.1949(0.1949) Grad: 344085.3438  LR: 0.00000513  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Step 0/1539 - Save Best Score: 0.4494 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [195/196] Elapsed 0m 24s (remain 0m 0s) Loss: 0.2291(0.2024) \n",
      "Epoch: [3][100/1539] Elapsed 1m 31s (remain 21m 43s) Loss: 0.2329(0.0832) Grad: 134323.5938  LR: 0.00000487  \n",
      "Epoch: [3][200/1539] Elapsed 2m 33s (remain 17m 2s) Loss: 0.0521(0.0864) Grad: 51454.2773  LR: 0.00000461  \n",
      "EVAL: [195/196] Elapsed 0m 24s (remain 0m 0s) Loss: 0.2253(0.2029) \n",
      "Epoch: [3][300/1539] Elapsed 3m 59s (remain 16m 26s) Loss: 0.0499(0.0855) Grad: 63939.5312  LR: 0.00000435  \n",
      "Epoch: [3][400/1539] Elapsed 5m 1s (remain 14m 16s) Loss: 0.0062(0.0843) Grad: 22739.7266  LR: 0.00000410  \n",
      "Epoch: [3][500/1539] Elapsed 6m 4s (remain 12m 35s) Loss: 0.0522(0.0843) Grad: 39790.3906  LR: 0.00000384  \n",
      "EVAL: [195/196] Elapsed 0m 24s (remain 0m 0s) Loss: 0.2313(0.2030) \n",
      "Epoch: [3][600/1539] Elapsed 7m 31s (remain 11m 44s) Loss: 0.1905(0.0831) Grad: 128200.6406  LR: 0.00000359  \n",
      "Epoch: [3][700/1539] Elapsed 8m 33s (remain 10m 13s) Loss: 0.1037(0.0842) Grad: 76223.9609  LR: 0.00000334  \n",
      "EVAL: [195/196] Elapsed 0m 25s (remain 0m 0s) Loss: 0.2315(0.2032) \n",
      "Epoch: [3][800/1539] Elapsed 9m 59s (remain 9m 12s) Loss: 0.2009(0.0839) Grad: 117582.2500  LR: 0.00000310  \n",
      "Epoch: [3][900/1539] Elapsed 11m 1s (remain 7m 48s) Loss: 0.1484(0.0873) Grad: 85850.1875  LR: 0.00000287  \n",
      "Epoch: [3][1000/1539] Elapsed 12m 3s (remain 6m 28s) Loss: 0.1298(0.0865) Grad: 39021.8438  LR: 0.00000263  \n",
      "EVAL: [195/196] Elapsed 0m 24s (remain 0m 0s) Loss: 0.2120(0.2053) \n",
      "Epoch: [3][1100/1539] Elapsed 13m 30s (remain 5m 22s) Loss: 0.0206(0.0863) Grad: 31389.6797  LR: 0.00000241  \n",
      "Epoch: [3][1200/1539] Elapsed 14m 34s (remain 4m 6s) Loss: 0.1303(0.0849) Grad: 97535.1484  LR: 0.00000219  \n",
      "EVAL: [195/196] Elapsed 0m 24s (remain 0m 0s) Loss: 0.2280(0.2030) \n",
      "Epoch: [3][1300/1539] Elapsed 16m 1s (remain 2m 55s) Loss: 0.0190(0.0855) Grad: 33843.8711  LR: 0.00000198  \n",
      "Epoch: [3][1400/1539] Elapsed 17m 3s (remain 1m 40s) Loss: 0.1702(0.0846) Grad: 82644.6016  LR: 0.00000178  \n",
      "Epoch: [3][1500/1539] Elapsed 18m 4s (remain 0m 27s) Loss: 0.0453(0.0847) Grad: 32138.0410  LR: 0.00000158  \n",
      "EVAL: [195/196] Elapsed 0m 25s (remain 0m 0s) Loss: 0.2437(0.2042) \n",
      "Epoch: [3][1538/1539] Elapsed 18m 53s (remain 0m 0s) Loss: 0.1227(0.0846) Grad: 49304.6133  LR: 0.00000151  \n",
      "EVAL: [195/196] Elapsed 0m 24s (remain 0m 0s) Loss: 0.2345(0.2031) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6157/6157 [00:05<00:00, 1200.12it/s]\n",
      "100%|██████████| 783/783 [00:00<00:00, 1312.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "783 (783, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "------------------- Start AWP --------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][0/1539] Elapsed 0m 1s (remain 34m 37s) Loss: 0.0056(0.0056) Grad: 65503.0391  LR: 0.00000151  \n",
      "EVAL: [195/196] Elapsed 0m 21s (remain 0m 0s) Loss: 0.2510(0.2034) \n",
      "Epoch: [4][100/1539] Elapsed 1m 21s (remain 19m 26s) Loss: 0.2063(0.0755) Grad: 188119.9219  LR: 0.00000133  \n",
      "Epoch: [4][200/1539] Elapsed 2m 20s (remain 15m 35s) Loss: 0.0542(0.0722) Grad: 118136.6250  LR: 0.00000116  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Step 250/1539 - Save Best Score: 0.4493 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [195/196] Elapsed 0m 21s (remain 0m 0s) Loss: 0.2393(0.2023) \n",
      "Epoch: [4][300/1539] Elapsed 3m 45s (remain 15m 26s) Loss: 0.0057(0.0711) Grad: 26966.2363  LR: 0.00000100  \n",
      "Epoch: [4][400/1539] Elapsed 4m 45s (remain 13m 30s) Loss: 0.1390(0.0725) Grad: 60284.1562  LR: 0.00000085  \n",
      "Epoch: [4][500/1539] Elapsed 5m 46s (remain 11m 56s) Loss: 0.0066(0.0727) Grad: 29242.6465  LR: 0.00000071  \n",
      "EVAL: [195/196] Elapsed 0m 21s (remain 0m 0s) Loss: 0.2476(0.2031) \n",
      "Epoch: [4][600/1539] Elapsed 7m 8s (remain 11m 9s) Loss: 0.0142(0.0777) Grad: 28957.0723  LR: 0.00000058  \n",
      "Epoch: [4][700/1539] Elapsed 8m 8s (remain 9m 43s) Loss: 0.1203(0.0780) Grad: 75589.8359  LR: 0.00000047  \n",
      "EVAL: [195/196] Elapsed 0m 21s (remain 0m 0s) Loss: 0.2435(0.2028) \n",
      "Epoch: [4][800/1539] Elapsed 9m 28s (remain 8m 43s) Loss: 0.1640(0.0771) Grad: 63749.5547  LR: 0.00000036  \n",
      "Epoch: [4][900/1539] Elapsed 10m 27s (remain 7m 24s) Loss: 0.0638(0.0765) Grad: 57095.7578  LR: 0.00000027  \n",
      "Epoch: [4][1000/1539] Elapsed 11m 27s (remain 6m 9s) Loss: 0.0655(0.0767) Grad: 52172.4102  LR: 0.00000019  \n",
      "EVAL: [195/196] Elapsed 0m 21s (remain 0m 0s) Loss: 0.2402(0.2028) \n",
      "Epoch: [4][1100/1539] Elapsed 12m 49s (remain 5m 5s) Loss: 0.0472(0.0768) Grad: 45960.0938  LR: 0.00000013  \n",
      "Epoch: [4][1200/1539] Elapsed 13m 49s (remain 3m 53s) Loss: 0.0199(0.0773) Grad: 33566.6211  LR: 0.00000008  \n",
      "EVAL: [195/196] Elapsed 0m 22s (remain 0m 0s) Loss: 0.2410(0.2028) \n",
      "Epoch: [4][1300/1539] Elapsed 15m 13s (remain 2m 47s) Loss: 0.0637(0.0777) Grad: 59774.7266  LR: 0.00000004  \n",
      "Epoch: [4][1400/1539] Elapsed 16m 13s (remain 1m 35s) Loss: 0.0907(0.0777) Grad: 30497.7266  LR: 0.00000001  \n",
      "Epoch: [4][1500/1539] Elapsed 17m 12s (remain 0m 26s) Loss: 0.0261(0.0766) Grad: 12366.4316  LR: 0.00000000  \n",
      "EVAL: [195/196] Elapsed 0m 21s (remain 0m 0s) Loss: 0.2403(0.2028) \n",
      "Epoch: [4][1538/1539] Elapsed 17m 56s (remain 0m 0s) Loss: 0.0799(0.0767) Grad: 25746.3770  LR: 0.00000000  \n",
      "EVAL: [195/196] Elapsed 0m 22s (remain 0m 0s) Loss: 0.2403(0.2028) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 1 result ==========\n",
      "Score: 0.4493\n",
      "========== fold: 2 training ==========\n",
      "Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['mask_predictions.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.classifier.bias']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 6157/6157 [00:05<00:00, 1146.78it/s]\n",
      "100%|██████████| 782/782 [00:00<00:00, 1229.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782 (782, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/1539] Elapsed 0m 1s (remain 26m 40s) Loss: 9.8026(9.8026) Grad: inf  LR: 0.00000010  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Step 0/1539 - Save Best Score: 2.9848 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [195/196] Elapsed 0m 21s (remain 0m 0s) Loss: 9.8770(9.0190) \n",
      "Epoch: [1][100/1539] Elapsed 1m 0s (remain 14m 16s) Loss: 0.2419(7.9128) Grad: 51256.1055  LR: 0.00001000  \n",
      "Epoch: [1][200/1539] Elapsed 1m 35s (remain 10m 37s) Loss: 0.2205(4.0740) Grad: 49634.8711  LR: 0.00000999  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Step 250/1539 - Save Best Score: 0.4882 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [195/196] Elapsed 0m 21s (remain 0m 0s) Loss: 0.1058(0.2389) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "------------------- Start AWP --------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][300/1539] Elapsed 2m 34s (remain 10m 37s) Loss: 0.0491(2.7744) Grad: 10576.3838  LR: 0.00000997  \n",
      "Epoch: [1][400/1539] Elapsed 3m 10s (remain 9m 0s) Loss: 0.1772(2.1219) Grad: 23042.4746  LR: 0.00000994  \n",
      "Epoch: [1][500/1539] Elapsed 3m 46s (remain 7m 48s) Loss: 0.0571(1.7211) Grad: 12117.0586  LR: 0.00000989  \n",
      "EVAL: [195/196] Elapsed 0m 22s (remain 0m 0s) Loss: 0.0834(0.2463) \n",
      "Epoch: [1][600/1539] Elapsed 4m 46s (remain 7m 26s) Loss: 0.1833(1.4553) Grad: 38396.9492  LR: 0.00000983  \n",
      "Epoch: [1][700/1539] Elapsed 5m 22s (remain 6m 25s) Loss: 0.0489(1.2652) Grad: 13993.6924  LR: 0.00000976  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Step 750/1539 - Save Best Score: 0.4704 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [195/196] Elapsed 0m 21s (remain 0m 0s) Loss: 0.1092(0.2217) \n",
      "Epoch: [1][800/1539] Elapsed 6m 23s (remain 5m 53s) Loss: 0.0946(1.1228) Grad: 21492.4668  LR: 0.00000967  \n",
      "Epoch: [1][900/1539] Elapsed 7m 0s (remain 4m 57s) Loss: 0.1401(1.0106) Grad: 16304.7119  LR: 0.00000957  \n",
      "Epoch: [1][1000/1539] Elapsed 7m 37s (remain 4m 5s) Loss: 0.0388(0.9205) Grad: 11764.2773  LR: 0.00000946  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Step 1000/1539 - Save Best Score: 0.4621 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [195/196] Elapsed 0m 21s (remain 0m 0s) Loss: 0.0769(0.2142) \n",
      "Epoch: [1][1100/1539] Elapsed 8m 38s (remain 3m 26s) Loss: 0.2621(0.8499) Grad: 18473.2207  LR: 0.00000934  \n",
      "Epoch: [1][1200/1539] Elapsed 9m 15s (remain 2m 36s) Loss: 0.0803(0.7894) Grad: 13791.4736  LR: 0.00000921  \n",
      "EVAL: [195/196] Elapsed 0m 21s (remain 0m 0s) Loss: 0.1437(0.2255) \n",
      "Epoch: [1][1300/1539] Elapsed 10m 14s (remain 1m 52s) Loss: 0.0445(0.7375) Grad: 6583.9272  LR: 0.00000906  \n",
      "Epoch: [1][1400/1539] Elapsed 10m 51s (remain 1m 4s) Loss: 0.1386(0.6936) Grad: 16260.3818  LR: 0.00000890  \n",
      "Epoch: [1][1500/1539] Elapsed 11m 27s (remain 0m 17s) Loss: 0.0477(0.6552) Grad: 14773.9209  LR: 0.00000874  \n",
      "EVAL: [195/196] Elapsed 0m 21s (remain 0m 0s) Loss: 0.0891(0.2204) \n",
      "Epoch: [1][1538/1539] Elapsed 12m 3s (remain 0m 0s) Loss: 0.2017(0.6420) Grad: 17029.4707  LR: 0.00000867  \n",
      "EVAL: [195/196] Elapsed 0m 22s (remain 0m 0s) Loss: 0.1031(0.2168) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6157/6157 [00:04<00:00, 1239.04it/s]\n",
      "100%|██████████| 782/782 [00:00<00:00, 1315.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782 (782, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "------------------- Start AWP --------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][0/1539] Elapsed 0m 1s (remain 34m 26s) Loss: 0.0870(0.0870) Grad: 322227.4688  LR: 0.00000867  \n",
      "EVAL: [195/196] Elapsed 0m 21s (remain 0m 0s) Loss: 0.1158(0.2205) \n",
      "Epoch: [2][100/1539] Elapsed 1m 22s (remain 19m 34s) Loss: 0.0549(0.0930) Grad: 137054.7188  LR: 0.00000849  \n",
      "Epoch: [2][200/1539] Elapsed 2m 22s (remain 15m 47s) Loss: 0.0659(0.0943) Grad: 82910.8516  LR: 0.00000830  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Step 250/1539 - Save Best Score: 0.4574 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [195/196] Elapsed 0m 22s (remain 0m 0s) Loss: 0.0719(0.2098) \n",
      "Epoch: [2][300/1539] Elapsed 3m 47s (remain 15m 34s) Loss: 0.0461(0.0909) Grad: 94110.4609  LR: 0.00000810  \n",
      "Epoch: [2][400/1539] Elapsed 4m 46s (remain 13m 33s) Loss: 0.1121(0.0888) Grad: 200661.1250  LR: 0.00000789  \n",
      "Epoch: [2][500/1539] Elapsed 5m 47s (remain 11m 59s) Loss: 0.0652(0.0867) Grad: 70831.1641  LR: 0.00000768  \n",
      "EVAL: [195/196] Elapsed 0m 21s (remain 0m 0s) Loss: 0.0626(0.2116) \n",
      "Epoch: [2][600/1539] Elapsed 7m 9s (remain 11m 10s) Loss: 0.0071(0.0846) Grad: 89333.2656  LR: 0.00000745  \n",
      "Epoch: [2][700/1539] Elapsed 8m 10s (remain 9m 46s) Loss: 0.0838(0.0850) Grad: 160045.6094  LR: 0.00000722  \n",
      "EVAL: [195/196] Elapsed 0m 21s (remain 0m 0s) Loss: 0.0687(0.2105) \n",
      "Epoch: [2][800/1539] Elapsed 9m 32s (remain 8m 47s) Loss: 0.0908(0.0850) Grad: 122208.8750  LR: 0.00000699  \n",
      "Epoch: [2][900/1539] Elapsed 10m 32s (remain 7m 28s) Loss: 0.0480(0.0849) Grad: 126129.5078  LR: 0.00000675  \n",
      "Epoch: [2][1000/1539] Elapsed 11m 33s (remain 6m 12s) Loss: 0.0403(0.0856) Grad: 84333.2031  LR: 0.00000650  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Step 1000/1539 - Save Best Score: 0.4572 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [195/196] Elapsed 0m 22s (remain 0m 0s) Loss: 0.0727(0.2096) \n",
      "Epoch: [2][1100/1539] Elapsed 12m 58s (remain 5m 9s) Loss: 0.0824(0.0870) Grad: 156053.0781  LR: 0.00000625  \n",
      "Epoch: [2][1200/1539] Elapsed 13m 57s (remain 3m 55s) Loss: 0.0472(0.0868) Grad: 86658.1641  LR: 0.00000600  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Step 1250/1539 - Save Best Score: 0.4567 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [195/196] Elapsed 0m 21s (remain 0m 0s) Loss: 0.0856(0.2091) \n",
      "Epoch: [2][1300/1539] Elapsed 15m 20s (remain 2m 48s) Loss: 0.0586(0.0860) Grad: 104437.6875  LR: 0.00000575  \n",
      "Epoch: [2][1400/1539] Elapsed 16m 20s (remain 1m 36s) Loss: 0.1084(0.0859) Grad: 176641.7656  LR: 0.00000549  \n",
      "Epoch: [2][1500/1539] Elapsed 17m 20s (remain 0m 26s) Loss: 0.0030(0.0868) Grad: 40579.3594  LR: 0.00000523  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Step 1500/1539 - Save Best Score: 0.4563 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [195/196] Elapsed 0m 21s (remain 0m 0s) Loss: 0.0850(0.2088) \n",
      "Epoch: [2][1538/1539] Elapsed 18m 6s (remain 0m 0s) Loss: 0.0990(0.0865) Grad: 166984.5312  LR: 0.00000513  \n",
      "EVAL: [195/196] Elapsed 0m 21s (remain 0m 0s) Loss: 0.0698(0.2093) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6157/6157 [00:05<00:00, 1211.32it/s]\n",
      "100%|██████████| 782/782 [00:00<00:00, 1312.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782 (782, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "------------------- Start AWP --------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][0/1539] Elapsed 0m 1s (remain 35m 36s) Loss: 0.0560(0.0560) Grad: 235967.8906  LR: 0.00000513  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Step 0/1539 - Save Best Score: 0.4557 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [195/196] Elapsed 0m 24s (remain 0m 0s) Loss: 0.0881(0.2083) \n",
      "Epoch: [3][100/1539] Elapsed 1m 30s (remain 21m 33s) Loss: 0.0525(0.0747) Grad: 81518.3281  LR: 0.00000487  \n",
      "Epoch: [3][200/1539] Elapsed 2m 32s (remain 16m 58s) Loss: 0.0546(0.0769) Grad: 80855.2891  LR: 0.00000461  \n",
      "EVAL: [195/196] Elapsed 0m 24s (remain 0m 0s) Loss: 0.1156(0.2087) \n",
      "Epoch: [3][300/1539] Elapsed 3m 59s (remain 16m 26s) Loss: 0.1028(0.0786) Grad: 185080.2188  LR: 0.00000435  \n",
      "Epoch: [3][400/1539] Elapsed 5m 2s (remain 14m 19s) Loss: 0.0585(0.0789) Grad: 99592.3203  LR: 0.00000410  \n",
      "Epoch: [3][500/1539] Elapsed 6m 6s (remain 12m 39s) Loss: 0.0155(0.0784) Grad: 68789.8984  LR: 0.00000384  \n",
      "EVAL: [195/196] Elapsed 0m 24s (remain 0m 0s) Loss: 0.1017(0.2086) \n",
      "Epoch: [3][600/1539] Elapsed 7m 34s (remain 11m 49s) Loss: 0.0669(0.0786) Grad: 125810.1641  LR: 0.00000359  \n",
      "Epoch: [3][700/1539] Elapsed 8m 37s (remain 10m 18s) Loss: 0.0149(0.0790) Grad: 51966.7773  LR: 0.00000334  \n",
      "EVAL: [195/196] Elapsed 0m 25s (remain 0m 0s) Loss: 0.0879(0.2096) \n",
      "Epoch: [3][800/1539] Elapsed 10m 5s (remain 9m 18s) Loss: 0.2231(0.0788) Grad: 184242.9062  LR: 0.00000310  \n",
      "Epoch: [3][900/1539] Elapsed 11m 8s (remain 7m 53s) Loss: 0.0884(0.0785) Grad: 120502.7109  LR: 0.00000287  \n",
      "Epoch: [3][1000/1539] Elapsed 12m 10s (remain 6m 32s) Loss: 0.1802(0.0788) Grad: 151004.2812  LR: 0.00000263  \n",
      "EVAL: [195/196] Elapsed 0m 24s (remain 0m 0s) Loss: 0.0921(0.2099) \n",
      "Epoch: [3][1100/1539] Elapsed 13m 36s (remain 5m 24s) Loss: 0.1996(0.0796) Grad: 207161.8750  LR: 0.00000241  \n",
      "Epoch: [3][1200/1539] Elapsed 14m 39s (remain 4m 7s) Loss: 0.0734(0.0792) Grad: 100538.5547  LR: 0.00000219  \n",
      "EVAL: [195/196] Elapsed 0m 24s (remain 0m 0s) Loss: 0.1006(0.2093) \n",
      "Epoch: [3][1300/1539] Elapsed 16m 6s (remain 2m 56s) Loss: 0.0608(0.0793) Grad: 120907.3672  LR: 0.00000198  \n",
      "Epoch: [3][1400/1539] Elapsed 17m 9s (remain 1m 41s) Loss: 0.1446(0.0799) Grad: 220428.6562  LR: 0.00000178  \n",
      "Epoch: [3][1500/1539] Elapsed 18m 12s (remain 0m 27s) Loss: 0.0879(0.0797) Grad: 169580.0938  LR: 0.00000158  \n",
      "EVAL: [195/196] Elapsed 0m 25s (remain 0m 0s) Loss: 0.0916(0.2091) \n",
      "Epoch: [3][1538/1539] Elapsed 19m 1s (remain 0m 0s) Loss: 0.0772(0.0802) Grad: 116558.2188  LR: 0.00000151  \n",
      "EVAL: [195/196] Elapsed 0m 24s (remain 0m 0s) Loss: 0.0842(0.2093) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6157/6157 [00:05<00:00, 1133.53it/s]\n",
      "100%|██████████| 782/782 [00:00<00:00, 1214.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782 (782, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------- Start AWP --------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][0/1539] Elapsed 0m 1s (remain 35m 5s) Loss: 0.1137(0.1137) Grad: 248702.5469  LR: 0.00000151  \n",
      "EVAL: [195/196] Elapsed 0m 21s (remain 0m 0s) Loss: 0.0685(0.2103) \n",
      "Epoch: [4][100/1539] Elapsed 1m 22s (remain 19m 37s) Loss: 0.0884(0.0789) Grad: 124308.3594  LR: 0.00000133  \n",
      "Epoch: [4][200/1539] Elapsed 2m 22s (remain 15m 49s) Loss: 0.0517(0.0745) Grad: 150350.2031  LR: 0.00000116  \n",
      "EVAL: [195/196] Elapsed 0m 21s (remain 0m 0s) Loss: 0.0851(0.2106) \n",
      "Epoch: [4][300/1539] Elapsed 3m 46s (remain 15m 29s) Loss: 0.0026(0.0721) Grad: 27309.8789  LR: 0.00000100  \n",
      "Epoch: [4][400/1539] Elapsed 4m 46s (remain 13m 34s) Loss: 0.0660(0.0730) Grad: 100740.0391  LR: 0.00000085  \n",
      "Epoch: [4][500/1539] Elapsed 5m 47s (remain 12m 0s) Loss: 0.1451(0.0741) Grad: 173338.2656  LR: 0.00000071  \n",
      "EVAL: [195/196] Elapsed 0m 21s (remain 0m 0s) Loss: 0.0780(0.2101) \n",
      "Epoch: [4][600/1539] Elapsed 7m 11s (remain 11m 13s) Loss: 0.0542(0.0734) Grad: 90397.2500  LR: 0.00000058  \n",
      "Epoch: [4][700/1539] Elapsed 8m 11s (remain 9m 47s) Loss: 0.1529(0.0745) Grad: 90869.5078  LR: 0.00000047  \n",
      "EVAL: [195/196] Elapsed 0m 21s (remain 0m 0s) Loss: 0.0739(0.2102) \n",
      "Epoch: [4][800/1539] Elapsed 9m 33s (remain 8m 48s) Loss: 0.2064(0.0752) Grad: 193511.9062  LR: 0.00000036  \n",
      "Epoch: [4][900/1539] Elapsed 10m 33s (remain 7m 28s) Loss: 0.1209(0.0735) Grad: 123764.1875  LR: 0.00000027  \n",
      "Epoch: [4][1000/1539] Elapsed 11m 35s (remain 6m 13s) Loss: 0.0249(0.0731) Grad: 61876.4570  LR: 0.00000019  \n",
      "EVAL: [195/196] Elapsed 0m 21s (remain 0m 0s) Loss: 0.0858(0.2104) \n",
      "Epoch: [4][1100/1539] Elapsed 12m 58s (remain 5m 9s) Loss: 0.0678(0.0729) Grad: 120383.5391  LR: 0.00000013  \n",
      "Epoch: [4][1200/1539] Elapsed 13m 58s (remain 3m 55s) Loss: 0.0684(0.0729) Grad: 123074.0469  LR: 0.00000008  \n",
      "EVAL: [195/196] Elapsed 0m 22s (remain 0m 0s) Loss: 0.0799(0.2101) \n",
      "Epoch: [4][1300/1539] Elapsed 15m 21s (remain 2m 48s) Loss: 0.0280(0.0737) Grad: 72901.6797  LR: 0.00000004  \n",
      "Epoch: [4][1400/1539] Elapsed 16m 22s (remain 1m 36s) Loss: 0.0785(0.0740) Grad: 67153.4219  LR: 0.00000001  \n",
      "Epoch: [4][1500/1539] Elapsed 17m 22s (remain 0m 26s) Loss: 0.0468(0.0743) Grad: 63061.1172  LR: 0.00000000  \n",
      "EVAL: [195/196] Elapsed 0m 21s (remain 0m 0s) Loss: 0.0787(0.2100) \n",
      "Epoch: [4][1538/1539] Elapsed 18m 7s (remain 0m 0s) Loss: 0.0171(0.0743) Grad: 52957.5156  LR: 0.00000000  \n",
      "EVAL: [195/196] Elapsed 0m 22s (remain 0m 0s) Loss: 0.0787(0.2100) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 2 result ==========\n",
      "Score: 0.4557\n",
      "========== fold: 3 training ==========\n",
      "Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['mask_predictions.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.classifier.bias']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 6157/6157 [00:05<00:00, 1126.47it/s]\n",
      "100%|██████████| 782/782 [00:00<00:00, 1220.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782 (782, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/1539] Elapsed 0m 1s (remain 26m 3s) Loss: 12.8599(12.8599) Grad: inf  LR: 0.00000010  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Step 0/1539 - Save Best Score: 2.9656 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [195/196] Elapsed 0m 21s (remain 0m 0s) Loss: 12.6761(8.9016) \n",
      "Epoch: [1][100/1539] Elapsed 1m 1s (remain 14m 31s) Loss: 0.5079(8.1187) Grad: 290934.6250  LR: 0.00001000  \n",
      "Epoch: [1][200/1539] Elapsed 1m 38s (remain 10m 54s) Loss: 0.1490(4.1751) Grad: 59722.8008  LR: 0.00000999  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Step 250/1539 - Save Best Score: 0.5579 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [195/196] Elapsed 0m 21s (remain 0m 0s) Loss: 0.0817(0.3118) \n",
      "Epoch: [1][300/1539] Elapsed 2m 38s (remain 10m 50s) Loss: 0.1213(2.8440) Grad: 36555.4844  LR: 0.00000997  \n",
      "Epoch: [1][400/1539] Elapsed 3m 14s (remain 9m 12s) Loss: 0.3310(2.1723) Grad: 127410.0703  LR: 0.00000994  \n",
      "Epoch: [1][500/1539] Elapsed 3m 50s (remain 7m 58s) Loss: 0.2761(1.7688) Grad: 77649.0234  LR: 0.00000989  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Step 500/1539 - Save Best Score: 0.5039 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [195/196] Elapsed 0m 22s (remain 0m 0s) Loss: 0.2019(0.2549) \n",
      "Epoch: [1][600/1539] Elapsed 4m 52s (remain 7m 36s) Loss: 0.1396(1.4967) Grad: 33833.2969  LR: 0.00000983  \n",
      "Epoch: [1][700/1539] Elapsed 5m 28s (remain 6m 32s) Loss: 0.1486(1.3022) Grad: 61238.3906  LR: 0.00000976  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Step 750/1539 - Save Best Score: 0.4643 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [195/196] Elapsed 0m 21s (remain 0m 0s) Loss: 0.1842(0.2163) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "------------------- Start AWP --------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][800/1539] Elapsed 6m 28s (remain 5m 58s) Loss: 0.1686(1.1561) Grad: 43811.5586  LR: 0.00000967  \n",
      "Epoch: [1][900/1539] Elapsed 7m 4s (remain 5m 0s) Loss: 0.1182(1.0411) Grad: 28054.0527  LR: 0.00000957  \n",
      "Epoch: [1][1000/1539] Elapsed 7m 41s (remain 4m 7s) Loss: 0.1245(0.9493) Grad: 45420.9805  LR: 0.00000946  \n",
      "EVAL: [195/196] Elapsed 0m 21s (remain 0m 0s) Loss: 0.1901(0.2239) \n",
      "Epoch: [1][1100/1539] Elapsed 8m 40s (remain 3m 26s) Loss: 0.1834(0.8760) Grad: 71590.0312  LR: 0.00000934  \n",
      "Epoch: [1][1200/1539] Elapsed 9m 16s (remain 2m 36s) Loss: 0.0937(0.8131) Grad: 31313.5918  LR: 0.00000921  \n",
      "EVAL: [195/196] Elapsed 0m 21s (remain 0m 0s) Loss: 0.1260(0.2211) \n",
      "Epoch: [1][1300/1539] Elapsed 10m 14s (remain 1m 52s) Loss: 0.0478(0.7590) Grad: 17585.3340  LR: 0.00000906  \n",
      "Epoch: [1][1400/1539] Elapsed 10m 51s (remain 1m 4s) Loss: 0.0445(0.7138) Grad: 20662.6973  LR: 0.00000890  \n",
      "Epoch: [1][1500/1539] Elapsed 11m 27s (remain 0m 17s) Loss: 0.1181(0.6740) Grad: 45424.8555  LR: 0.00000874  \n",
      "EVAL: [195/196] Elapsed 0m 21s (remain 0m 0s) Loss: 0.1691(0.2163) \n",
      "Epoch: [1][1538/1539] Elapsed 12m 3s (remain 0m 0s) Loss: 0.1119(0.6608) Grad: 12319.5322  LR: 0.00000867  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Step 1538/1539 - Save Best Score: 0.4569 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [195/196] Elapsed 0m 22s (remain 0m 0s) Loss: 0.2003(0.2093) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6157/6157 [00:05<00:00, 1229.09it/s]\n",
      "100%|██████████| 782/782 [00:00<00:00, 1293.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782 (782, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "------------------- Start AWP --------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][0/1539] Elapsed 0m 1s (remain 32m 23s) Loss: 0.2010(0.2010) Grad: 456180.5938  LR: 0.00000867  \n",
      "EVAL: [195/196] Elapsed 0m 21s (remain 0m 0s) Loss: 0.2133(0.2120) \n",
      "Epoch: [2][100/1539] Elapsed 1m 22s (remain 19m 35s) Loss: 0.1115(0.1091) Grad: 107808.3516  LR: 0.00000849  \n",
      "Epoch: [2][200/1539] Elapsed 2m 22s (remain 15m 51s) Loss: 0.1197(0.0996) Grad: 130188.2188  LR: 0.00000830  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Step 250/1539 - Save Best Score: 0.4496 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [195/196] Elapsed 0m 22s (remain 0m 0s) Loss: 0.1677(0.2028) \n",
      "Epoch: [2][300/1539] Elapsed 3m 48s (remain 15m 38s) Loss: 0.0359(0.1036) Grad: 60606.0859  LR: 0.00000810  \n",
      "Epoch: [2][400/1539] Elapsed 4m 48s (remain 13m 39s) Loss: 0.0688(0.1018) Grad: 103291.5156  LR: 0.00000789  \n",
      "Epoch: [2][500/1539] Elapsed 5m 49s (remain 12m 3s) Loss: 0.1879(0.0989) Grad: 99368.5234  LR: 0.00000768  \n",
      "EVAL: [195/196] Elapsed 0m 21s (remain 0m 0s) Loss: 0.1714(0.2087) \n",
      "Epoch: [2][600/1539] Elapsed 7m 10s (remain 11m 12s) Loss: 0.0836(0.0985) Grad: 90697.5234  LR: 0.00000745  \n",
      "Epoch: [2][700/1539] Elapsed 8m 13s (remain 9m 49s) Loss: 0.2895(0.0990) Grad: 62507.7734  LR: 0.00000722  \n",
      "EVAL: [195/196] Elapsed 0m 21s (remain 0m 0s) Loss: 0.1828(0.2069) \n",
      "Epoch: [2][800/1539] Elapsed 9m 35s (remain 8m 50s) Loss: 0.0646(0.0994) Grad: 25209.9316  LR: 0.00000699  \n",
      "Epoch: [2][900/1539] Elapsed 10m 35s (remain 7m 30s) Loss: 0.0837(0.0996) Grad: 34850.2500  LR: 0.00000675  \n",
      "Epoch: [2][1000/1539] Elapsed 11m 36s (remain 6m 14s) Loss: 0.0836(0.1024) Grad: 16218.4902  LR: 0.00000650  \n",
      "EVAL: [195/196] Elapsed 0m 22s (remain 0m 0s) Loss: 0.2060(0.2228) \n",
      "Epoch: [2][1100/1539] Elapsed 12m 59s (remain 5m 10s) Loss: 0.0312(0.1027) Grad: 12912.4150  LR: 0.00000625  \n",
      "Epoch: [2][1200/1539] Elapsed 13m 59s (remain 3m 56s) Loss: 0.2326(0.1030) Grad: 29425.4883  LR: 0.00000600  \n",
      "EVAL: [195/196] Elapsed 0m 21s (remain 0m 0s) Loss: 0.1719(0.2211) \n",
      "Epoch: [2][1300/1539] Elapsed 15m 22s (remain 2m 48s) Loss: 0.2681(0.1030) Grad: 18375.2051  LR: 0.00000575  \n",
      "Epoch: [2][1400/1539] Elapsed 16m 23s (remain 1m 36s) Loss: 0.0802(0.1029) Grad: 12555.2119  LR: 0.00000549  \n",
      "Epoch: [2][1500/1539] Elapsed 17m 23s (remain 0m 26s) Loss: 0.0459(0.1030) Grad: 9503.5176  LR: 0.00000523  \n",
      "EVAL: [195/196] Elapsed 0m 21s (remain 0m 0s) Loss: 0.1353(0.2157) \n",
      "Epoch: [2][1538/1539] Elapsed 18m 8s (remain 0m 0s) Loss: 0.0689(0.1027) Grad: 17002.8906  LR: 0.00000513  \n",
      "EVAL: [195/196] Elapsed 0m 21s (remain 0m 0s) Loss: 0.1423(0.2089) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6157/6157 [00:05<00:00, 1187.01it/s]\n",
      "100%|██████████| 782/782 [00:00<00:00, 1280.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782 (782, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "------------------- Start AWP --------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][0/1539] Elapsed 0m 1s (remain 35m 8s) Loss: 0.1022(0.1022) Grad: 294377.8438  LR: 0.00000513  \n",
      "EVAL: [195/196] Elapsed 0m 24s (remain 0m 0s) Loss: 0.1305(0.2070) \n",
      "Epoch: [3][100/1539] Elapsed 1m 30s (remain 21m 27s) Loss: 0.1121(0.0892) Grad: 188759.7656  LR: 0.00000487  \n",
      "Epoch: [3][200/1539] Elapsed 2m 32s (remain 16m 55s) Loss: 0.0694(0.0840) Grad: 114350.1484  LR: 0.00000461  \n",
      "EVAL: [195/196] Elapsed 0m 24s (remain 0m 0s) Loss: 0.1457(0.2032) \n",
      "Epoch: [3][300/1539] Elapsed 4m 0s (remain 16m 28s) Loss: 0.1966(0.0793) Grad: 229651.8125  LR: 0.00000435  \n",
      "Epoch: [3][400/1539] Elapsed 5m 2s (remain 14m 17s) Loss: 0.0891(0.0795) Grad: 115649.6016  LR: 0.00000410  \n",
      "Epoch: [3][500/1539] Elapsed 6m 6s (remain 12m 38s) Loss: 0.0871(0.0818) Grad: 96877.8125  LR: 0.00000384  \n",
      "EVAL: [195/196] Elapsed 0m 24s (remain 0m 0s) Loss: 0.1330(0.2030) \n",
      "Epoch: [3][600/1539] Elapsed 7m 33s (remain 11m 48s) Loss: 0.1172(0.0810) Grad: 101203.4219  LR: 0.00000359  \n",
      "Epoch: [3][700/1539] Elapsed 8m 36s (remain 10m 16s) Loss: 0.1493(0.0807) Grad: 223225.3750  LR: 0.00000334  \n",
      "EVAL: [195/196] Elapsed 0m 25s (remain 0m 0s) Loss: 0.1336(0.2029) \n",
      "Epoch: [3][800/1539] Elapsed 10m 5s (remain 9m 17s) Loss: 0.0582(0.0809) Grad: 64793.5352  LR: 0.00000310  \n",
      "Epoch: [3][900/1539] Elapsed 11m 8s (remain 7m 53s) Loss: 0.0257(0.0796) Grad: 90694.4922  LR: 0.00000287  \n",
      "Epoch: [3][1000/1539] Elapsed 12m 11s (remain 6m 33s) Loss: 0.2715(0.0795) Grad: 257671.6562  LR: 0.00000263  \n",
      "EVAL: [195/196] Elapsed 0m 24s (remain 0m 0s) Loss: 0.1429(0.2029) \n",
      "Epoch: [3][1100/1539] Elapsed 13m 38s (remain 5m 25s) Loss: 0.1280(0.0801) Grad: 88481.7500  LR: 0.00000241  \n",
      "Epoch: [3][1200/1539] Elapsed 14m 41s (remain 4m 8s) Loss: 0.0820(0.0793) Grad: 54929.6523  LR: 0.00000219  \n",
      "EVAL: [195/196] Elapsed 0m 24s (remain 0m 0s) Loss: 0.1312(0.2047) \n",
      "Epoch: [3][1300/1539] Elapsed 16m 9s (remain 2m 57s) Loss: 0.0751(0.0788) Grad: 68188.4297  LR: 0.00000198  \n",
      "Epoch: [3][1400/1539] Elapsed 17m 11s (remain 1m 41s) Loss: 0.0902(0.0785) Grad: 71737.0469  LR: 0.00000178  \n",
      "Epoch: [3][1500/1539] Elapsed 18m 14s (remain 0m 27s) Loss: 0.0245(0.0783) Grad: 15517.8838  LR: 0.00000158  \n",
      "EVAL: [195/196] Elapsed 0m 25s (remain 0m 0s) Loss: 0.1533(0.2038) \n",
      "Epoch: [3][1538/1539] Elapsed 19m 3s (remain 0m 0s) Loss: 0.1068(0.0784) Grad: 34319.0508  LR: 0.00000151  \n",
      "EVAL: [195/196] Elapsed 0m 24s (remain 0m 0s) Loss: 0.1598(0.2035) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6157/6157 [00:05<00:00, 1185.24it/s]\n",
      "100%|██████████| 782/782 [00:00<00:00, 1290.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782 (782, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "------------------- Start AWP --------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][0/1539] Elapsed 0m 1s (remain 35m 40s) Loss: 0.1275(0.1275) Grad: 246645.7188  LR: 0.00000151  \n",
      "EVAL: [195/196] Elapsed 0m 21s (remain 0m 0s) Loss: 0.1629(0.2036) \n",
      "Epoch: [4][100/1539] Elapsed 1m 23s (remain 19m 48s) Loss: 0.0810(0.0748) Grad: 226945.6719  LR: 0.00000133  \n",
      "Epoch: [4][200/1539] Elapsed 2m 23s (remain 15m 58s) Loss: 0.1075(0.0656) Grad: 243416.8750  LR: 0.00000116  \n",
      "EVAL: [195/196] Elapsed 0m 21s (remain 0m 0s) Loss: 0.1510(0.2027) \n",
      "Epoch: [4][300/1539] Elapsed 3m 47s (remain 15m 34s) Loss: 0.0333(0.0669) Grad: 83671.4922  LR: 0.00000100  \n",
      "Epoch: [4][400/1539] Elapsed 4m 48s (remain 13m 37s) Loss: 0.0551(0.0678) Grad: 121773.0234  LR: 0.00000085  \n",
      "Epoch: [4][500/1539] Elapsed 5m 48s (remain 12m 2s) Loss: 0.0560(0.0690) Grad: 93942.7812  LR: 0.00000071  \n",
      "EVAL: [195/196] Elapsed 0m 21s (remain 0m 0s) Loss: 0.1474(0.2028) \n",
      "Epoch: [4][600/1539] Elapsed 7m 11s (remain 11m 13s) Loss: 0.0759(0.0702) Grad: 150651.7500  LR: 0.00000058  \n",
      "Epoch: [4][700/1539] Elapsed 8m 11s (remain 9m 47s) Loss: 0.0807(0.0699) Grad: 68899.8672  LR: 0.00000047  \n",
      "EVAL: [195/196] Elapsed 0m 21s (remain 0m 0s) Loss: 0.1442(0.2030) \n",
      "Epoch: [4][800/1539] Elapsed 9m 34s (remain 8m 48s) Loss: 0.0941(0.0696) Grad: 54641.5547  LR: 0.00000036  \n",
      "Epoch: [4][900/1539] Elapsed 10m 34s (remain 7m 28s) Loss: 0.0911(0.0696) Grad: 59029.1172  LR: 0.00000027  \n",
      "Epoch: [4][1000/1539] Elapsed 11m 35s (remain 6m 13s) Loss: 0.1254(0.0702) Grad: 102837.9453  LR: 0.00000019  \n",
      "EVAL: [195/196] Elapsed 0m 21s (remain 0m 0s) Loss: 0.1485(0.2030) \n",
      "Epoch: [4][1100/1539] Elapsed 12m 56s (remain 5m 8s) Loss: 0.1419(0.0701) Grad: 85635.8438  LR: 0.00000013  \n",
      "Epoch: [4][1200/1539] Elapsed 13m 56s (remain 3m 55s) Loss: 0.0766(0.0712) Grad: 66962.7109  LR: 0.00000008  \n",
      "EVAL: [195/196] Elapsed 0m 22s (remain 0m 0s) Loss: 0.1476(0.2029) \n",
      "Epoch: [4][1300/1539] Elapsed 15m 19s (remain 2m 48s) Loss: 0.1167(0.0708) Grad: 52082.2812  LR: 0.00000004  \n",
      "Epoch: [4][1400/1539] Elapsed 16m 20s (remain 1m 36s) Loss: 0.0596(0.0712) Grad: 38777.5469  LR: 0.00000001  \n",
      "Epoch: [4][1500/1539] Elapsed 17m 19s (remain 0m 26s) Loss: 0.0191(0.0706) Grad: 16413.3086  LR: 0.00000000  \n",
      "EVAL: [195/196] Elapsed 0m 21s (remain 0m 0s) Loss: 0.1481(0.2029) \n",
      "Epoch: [4][1538/1539] Elapsed 18m 3s (remain 0m 0s) Loss: 0.0839(0.0709) Grad: 31491.7852  LR: 0.00000000  \n",
      "EVAL: [195/196] Elapsed 0m 23s (remain 0m 0s) Loss: 0.1481(0.2029) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 3 result ==========\n",
      "Score: 0.4496\n",
      "========== fold: 4 training ==========\n",
      "Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['mask_predictions.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.classifier.bias']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 6157/6157 [00:05<00:00, 1152.47it/s]\n",
      "100%|██████████| 782/782 [00:00<00:00, 1207.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782 (782, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/1539] Elapsed 0m 1s (remain 26m 41s) Loss: 10.9333(10.9333) Grad: inf  LR: 0.00000010  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Step 0/1539 - Save Best Score: 2.9818 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [195/196] Elapsed 0m 21s (remain 0m 0s) Loss: 9.0209(9.0020) \n",
      "Epoch: [1][100/1539] Elapsed 1m 1s (remain 14m 31s) Loss: 0.3195(8.1398) Grad: 46228.6523  LR: 0.00001000  \n",
      "Epoch: [1][200/1539] Elapsed 1m 38s (remain 10m 53s) Loss: 0.1523(4.1826) Grad: 36210.8750  LR: 0.00000999  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Step 250/1539 - Save Best Score: 0.4892 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [195/196] Elapsed 0m 21s (remain 0m 0s) Loss: 0.1888(0.2403) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "------------------- Start AWP --------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][300/1539] Elapsed 2m 37s (remain 10m 48s) Loss: 0.1601(2.8501) Grad: 39358.2031  LR: 0.00000997  \n",
      "Epoch: [1][400/1539] Elapsed 3m 13s (remain 9m 9s) Loss: 0.2930(2.1772) Grad: 32382.6250  LR: 0.00000994  \n",
      "Epoch: [1][500/1539] Elapsed 3m 49s (remain 7m 54s) Loss: 0.0769(1.7710) Grad: 13112.9453  LR: 0.00000989  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Step 500/1539 - Save Best Score: 0.4687 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [195/196] Elapsed 0m 22s (remain 0m 0s) Loss: 0.1746(0.2203) \n",
      "Epoch: [1][600/1539] Elapsed 4m 50s (remain 7m 32s) Loss: 0.1177(1.4982) Grad: 15370.6738  LR: 0.00000983  \n",
      "Epoch: [1][700/1539] Elapsed 5m 26s (remain 6m 30s) Loss: 0.0352(1.3014) Grad: 9315.8232  LR: 0.00000976  \n",
      "EVAL: [195/196] Elapsed 0m 21s (remain 0m 0s) Loss: 0.1912(0.2227) \n",
      "Epoch: [1][800/1539] Elapsed 6m 24s (remain 5m 54s) Loss: 0.2212(1.1548) Grad: 20841.5820  LR: 0.00000967  \n",
      "Epoch: [1][900/1539] Elapsed 7m 0s (remain 4m 57s) Loss: 0.0893(1.0396) Grad: 16884.2871  LR: 0.00000957  \n",
      "Epoch: [1][1000/1539] Elapsed 7m 36s (remain 4m 5s) Loss: 0.0972(0.9470) Grad: 15633.8623  LR: 0.00000946  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Step 1000/1539 - Save Best Score: 0.4619 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [195/196] Elapsed 0m 21s (remain 0m 0s) Loss: 0.2094(0.2138) \n",
      "Epoch: [1][1100/1539] Elapsed 8m 37s (remain 3m 26s) Loss: 0.1019(0.8728) Grad: 21465.0195  LR: 0.00000934  \n",
      "Epoch: [1][1200/1539] Elapsed 9m 14s (remain 2m 36s) Loss: 0.2161(0.8103) Grad: 15186.3125  LR: 0.00000921  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Step 1250/1539 - Save Best Score: 0.4541 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [195/196] Elapsed 0m 21s (remain 0m 0s) Loss: 0.1272(0.2068) \n",
      "Epoch: [1][1300/1539] Elapsed 10m 14s (remain 1m 52s) Loss: 0.1583(0.7578) Grad: 24000.1777  LR: 0.00000906  \n",
      "Epoch: [1][1400/1539] Elapsed 10m 50s (remain 1m 4s) Loss: 0.1356(0.7114) Grad: 15447.2686  LR: 0.00000890  \n",
      "Epoch: [1][1500/1539] Elapsed 11m 28s (remain 0m 17s) Loss: 0.0557(0.6722) Grad: 10375.4434  LR: 0.00000874  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Step 1500/1539 - Save Best Score: 0.4475 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [195/196] Elapsed 0m 21s (remain 0m 0s) Loss: 0.1592(0.2007) \n",
      "Epoch: [1][1538/1539] Elapsed 12m 5s (remain 0m 0s) Loss: 0.0848(0.6584) Grad: 16190.4111  LR: 0.00000867  \n",
      "EVAL: [195/196] Elapsed 0m 22s (remain 0m 0s) Loss: 0.1826(0.2078) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6157/6157 [00:04<00:00, 1254.06it/s]\n",
      "100%|██████████| 782/782 [00:00<00:00, 1308.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782 (782, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "------------------- Start AWP --------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][0/1539] Elapsed 0m 1s (remain 34m 59s) Loss: 0.0755(0.0755) Grad: 272091.4688  LR: 0.00000867  \n",
      "EVAL: [195/196] Elapsed 0m 21s (remain 0m 0s) Loss: 0.1811(0.2077) \n",
      "Epoch: [2][100/1539] Elapsed 1m 22s (remain 19m 33s) Loss: 0.0676(0.0974) Grad: 70843.9219  LR: 0.00000849  \n",
      "Epoch: [2][200/1539] Elapsed 2m 21s (remain 15m 40s) Loss: 0.0345(0.0929) Grad: 72870.9531  LR: 0.00000830  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Step 250/1539 - Save Best Score: 0.4467 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [195/196] Elapsed 0m 22s (remain 0m 0s) Loss: 0.1315(0.2000) \n",
      "Epoch: [2][300/1539] Elapsed 3m 45s (remain 15m 25s) Loss: 0.0929(0.0922) Grad: 121632.7656  LR: 0.00000810  \n",
      "Epoch: [2][400/1539] Elapsed 4m 44s (remain 13m 26s) Loss: 0.0923(0.0916) Grad: 140961.7188  LR: 0.00000789  \n",
      "Epoch: [2][500/1539] Elapsed 5m 43s (remain 11m 52s) Loss: 0.0771(0.0912) Grad: 113142.6172  LR: 0.00000768  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Step 500/1539 - Save Best Score: 0.4451 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [195/196] Elapsed 0m 21s (remain 0m 0s) Loss: 0.1413(0.1985) \n",
      "Epoch: [2][600/1539] Elapsed 7m 8s (remain 11m 8s) Loss: 0.1670(0.0906) Grad: 105371.7812  LR: 0.00000745  \n",
      "Epoch: [2][700/1539] Elapsed 8m 9s (remain 9m 45s) Loss: 0.0239(0.0888) Grad: 84871.6172  LR: 0.00000722  \n",
      "EVAL: [195/196] Elapsed 0m 21s (remain 0m 0s) Loss: 0.1272(0.2005) \n",
      "Epoch: [2][800/1539] Elapsed 9m 30s (remain 8m 46s) Loss: 0.0831(0.0890) Grad: 142478.4062  LR: 0.00000699  \n",
      "Epoch: [2][900/1539] Elapsed 10m 30s (remain 7m 26s) Loss: 0.1235(0.0886) Grad: 132466.5312  LR: 0.00000675  \n",
      "Epoch: [2][1000/1539] Elapsed 11m 29s (remain 6m 10s) Loss: 0.2011(0.0895) Grad: 112298.4453  LR: 0.00000650  \n",
      "EVAL: [195/196] Elapsed 0m 22s (remain 0m 0s) Loss: 0.1355(0.1986) \n",
      "Epoch: [2][1100/1539] Elapsed 12m 53s (remain 5m 7s) Loss: 0.0586(0.0897) Grad: 83806.8125  LR: 0.00000625  \n",
      "Epoch: [2][1200/1539] Elapsed 13m 53s (remain 3m 54s) Loss: 0.0507(0.0896) Grad: 80747.8828  LR: 0.00000600  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Step 1250/1539 - Save Best Score: 0.4445 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [195/196] Elapsed 0m 21s (remain 0m 0s) Loss: 0.1554(0.1979) \n",
      "Epoch: [2][1300/1539] Elapsed 15m 18s (remain 2m 48s) Loss: 0.0914(0.0892) Grad: 150266.0938  LR: 0.00000575  \n",
      "Epoch: [2][1400/1539] Elapsed 16m 20s (remain 1m 36s) Loss: 0.0812(0.0892) Grad: 109347.0781  LR: 0.00000549  \n",
      "Epoch: [2][1500/1539] Elapsed 17m 19s (remain 0m 26s) Loss: 0.0757(0.0892) Grad: 113348.1641  LR: 0.00000523  \n",
      "EVAL: [195/196] Elapsed 0m 21s (remain 0m 0s) Loss: 0.1253(0.1987) \n",
      "Epoch: [2][1538/1539] Elapsed 18m 3s (remain 0m 0s) Loss: 0.0450(0.0892) Grad: 76725.2188  LR: 0.00000513  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Step 1538/1539 - Save Best Score: 0.4430 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [195/196] Elapsed 0m 21s (remain 0m 0s) Loss: 0.1372(0.1966) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6157/6157 [00:05<00:00, 1139.75it/s]\n",
      "100%|██████████| 782/782 [00:00<00:00, 1198.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782 (782, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------- Start AWP --------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][0/1539] Elapsed 0m 1s (remain 36m 6s) Loss: 0.0331(0.0331) Grad: 188270.7344  LR: 0.00000513  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Step 0/1539 - Save Best Score: 0.4429 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [195/196] Elapsed 0m 24s (remain 0m 0s) Loss: 0.1340(0.1966) \n",
      "Epoch: [3][100/1539] Elapsed 1m 31s (remain 21m 37s) Loss: 0.1133(0.0798) Grad: 273234.8750  LR: 0.00000487  \n",
      "Epoch: [3][200/1539] Elapsed 2m 33s (remain 17m 3s) Loss: 0.0292(0.0800) Grad: 201894.4688  LR: 0.00000461  \n",
      "EVAL: [195/196] Elapsed 0m 24s (remain 0m 0s) Loss: 0.1435(0.1968) \n",
      "Epoch: [3][300/1539] Elapsed 4m 0s (remain 16m 27s) Loss: 0.0383(0.0807) Grad: 119773.1016  LR: 0.00000435  \n",
      "Epoch: [3][400/1539] Elapsed 5m 3s (remain 14m 20s) Loss: 0.0609(0.0803) Grad: 127953.4922  LR: 0.00000410  \n",
      "Epoch: [3][500/1539] Elapsed 6m 7s (remain 12m 41s) Loss: 0.0796(0.0831) Grad: 129478.7812  LR: 0.00000384  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Step 500/1539 - Save Best Score: 0.4429 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [195/196] Elapsed 0m 24s (remain 0m 0s) Loss: 0.1376(0.1965) \n",
      "Epoch: [3][600/1539] Elapsed 7m 37s (remain 11m 53s) Loss: 0.0907(0.0834) Grad: 152783.3594  LR: 0.00000359  \n",
      "Epoch: [3][700/1539] Elapsed 8m 39s (remain 10m 21s) Loss: 0.0966(0.0837) Grad: 46897.5547  LR: 0.00000334  \n",
      "EVAL: [195/196] Elapsed 0m 25s (remain 0m 0s) Loss: 0.1234(0.2001) \n",
      "Epoch: [3][800/1539] Elapsed 10m 8s (remain 9m 20s) Loss: 0.0778(0.0829) Grad: 43258.3906  LR: 0.00000310  \n",
      "Epoch: [3][900/1539] Elapsed 11m 10s (remain 7m 54s) Loss: 0.0956(0.0828) Grad: 77340.7031  LR: 0.00000287  \n",
      "Epoch: [3][1000/1539] Elapsed 12m 13s (remain 6m 34s) Loss: 0.0866(0.0832) Grad: 68579.3594  LR: 0.00000263  \n",
      "EVAL: [195/196] Elapsed 0m 24s (remain 0m 0s) Loss: 0.1451(0.1967) \n",
      "Epoch: [3][1100/1539] Elapsed 13m 41s (remain 5m 26s) Loss: 0.0060(0.0829) Grad: 49390.4766  LR: 0.00000241  \n",
      "Epoch: [3][1200/1539] Elapsed 14m 46s (remain 4m 9s) Loss: 0.0394(0.0830) Grad: 53969.0039  LR: 0.00000219  \n",
      "EVAL: [195/196] Elapsed 0m 24s (remain 0m 0s) Loss: 0.1412(0.1970) \n",
      "Epoch: [3][1300/1539] Elapsed 16m 12s (remain 2m 57s) Loss: 0.2350(0.0841) Grad: 53419.3125  LR: 0.00000198  \n",
      "Epoch: [3][1400/1539] Elapsed 17m 15s (remain 1m 42s) Loss: 0.0406(0.0843) Grad: 28420.1328  LR: 0.00000178  \n",
      "Epoch: [3][1500/1539] Elapsed 18m 17s (remain 0m 27s) Loss: 0.1924(0.0839) Grad: 53652.2578  LR: 0.00000158  \n",
      "EVAL: [195/196] Elapsed 0m 25s (remain 0m 0s) Loss: 0.1325(0.2006) \n",
      "Epoch: [3][1538/1539] Elapsed 19m 7s (remain 0m 0s) Loss: 0.0970(0.0838) Grad: 70151.0078  LR: 0.00000151  \n",
      "EVAL: [195/196] Elapsed 0m 24s (remain 0m 0s) Loss: 0.1391(0.1976) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6157/6157 [00:05<00:00, 1145.19it/s]\n",
      "100%|██████████| 782/782 [00:00<00:00, 1202.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782 (782, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------- Start AWP --------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][0/1539] Elapsed 0m 1s (remain 35m 29s) Loss: 0.0967(0.0967) Grad: 232378.1406  LR: 0.00000151  \n",
      "EVAL: [195/196] Elapsed 0m 21s (remain 0m 0s) Loss: 0.1398(0.1976) \n",
      "Epoch: [4][100/1539] Elapsed 1m 24s (remain 19m 59s) Loss: 0.1519(0.0851) Grad: 356525.2812  LR: 0.00000133  \n",
      "Epoch: [4][200/1539] Elapsed 2m 24s (remain 15m 59s) Loss: 0.0027(0.0765) Grad: 107570.4766  LR: 0.00000116  \n",
      "EVAL: [195/196] Elapsed 0m 21s (remain 0m 0s) Loss: 0.1409(0.1966) \n",
      "Epoch: [4][300/1539] Elapsed 3m 46s (remain 15m 33s) Loss: 0.0386(0.0747) Grad: 182123.1094  LR: 0.00000100  \n",
      "Epoch: [4][400/1539] Elapsed 4m 46s (remain 13m 34s) Loss: 0.2092(0.0739) Grad: 371399.0000  LR: 0.00000085  \n",
      "Epoch: [4][500/1539] Elapsed 5m 46s (remain 11m 58s) Loss: 0.1808(0.0755) Grad: 299562.7812  LR: 0.00000071  \n",
      "EVAL: [195/196] Elapsed 0m 21s (remain 0m 0s) Loss: 0.1406(0.1974) \n",
      "Epoch: [4][600/1539] Elapsed 7m 10s (remain 11m 11s) Loss: 0.0549(0.0754) Grad: 220431.7344  LR: 0.00000058  \n",
      "Epoch: [4][700/1539] Elapsed 8m 10s (remain 9m 46s) Loss: 0.1383(0.0745) Grad: 286691.6250  LR: 0.00000047  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Step 750/1539 - Save Best Score: 0.4429 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [195/196] Elapsed 0m 21s (remain 0m 0s) Loss: 0.1449(0.1965) \n",
      "Epoch: [4][800/1539] Elapsed 9m 34s (remain 8m 49s) Loss: 0.0042(0.0745) Grad: 128234.0312  LR: 0.00000036  \n",
      "Epoch: [4][900/1539] Elapsed 10m 35s (remain 7m 30s) Loss: 0.2112(0.0747) Grad: 414776.8750  LR: 0.00000027  \n",
      "Epoch: [4][1000/1539] Elapsed 11m 36s (remain 6m 14s) Loss: 0.0832(0.0749) Grad: 123096.0781  LR: 0.00000019  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Step 1000/1539 - Save Best Score: 0.4427 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [195/196] Elapsed 0m 21s (remain 0m 0s) Loss: 0.1443(0.1964) \n",
      "Epoch: [4][1100/1539] Elapsed 13m 1s (remain 5m 10s) Loss: 0.0543(0.0748) Grad: 102284.5312  LR: 0.00000013  \n",
      "Epoch: [4][1200/1539] Elapsed 14m 2s (remain 3m 57s) Loss: 0.0021(0.0756) Grad: 35553.8945  LR: 0.00000008  \n",
      "EVAL: [195/196] Elapsed 0m 22s (remain 0m 0s) Loss: 0.1415(0.1965) \n",
      "Epoch: [4][1300/1539] Elapsed 15m 25s (remain 2m 49s) Loss: 0.1578(0.0758) Grad: 165586.1875  LR: 0.00000004  \n",
      "Epoch: [4][1400/1539] Elapsed 16m 26s (remain 1m 37s) Loss: 0.0181(0.0766) Grad: 32381.0156  LR: 0.00000001  \n",
      "Epoch: [4][1500/1539] Elapsed 17m 26s (remain 0m 26s) Loss: 0.0340(0.0765) Grad: 47045.3398  LR: 0.00000000  \n",
      "EVAL: [195/196] Elapsed 0m 21s (remain 0m 0s) Loss: 0.1412(0.1966) \n",
      "Epoch: [4][1538/1539] Elapsed 18m 10s (remain 0m 0s) Loss: 0.0953(0.0764) Grad: 58932.4844  LR: 0.00000000  \n",
      "EVAL: [195/196] Elapsed 0m 22s (remain 0m 0s) Loss: 0.1412(0.1966) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 4 result ==========\n",
      "Score: 0.4427\n",
      "========== CV ==========\n",
      "Score: 0.4480\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "322a30774f004ccca7d7aa40958353ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>[fold0] loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>[fold0] lr</td><td>▅██████▇▇▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>[fold1] loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>[fold1] lr</td><td>▅██████▇▇▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>[fold2] loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>[fold2] lr</td><td>▅██████▇▇▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>[fold3] loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>[fold3] lr</td><td>▅██████▇▇▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>[fold4] loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>[fold4] lr</td><td>▅██████▇▇▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>[fold0] loss</td><td>0.06943</td></tr><tr><td>[fold0] lr</td><td>0.0</td></tr><tr><td>[fold1] loss</td><td>0.07988</td></tr><tr><td>[fold1] lr</td><td>0.0</td></tr><tr><td>[fold2] loss</td><td>0.01709</td></tr><tr><td>[fold2] lr</td><td>0.0</td></tr><tr><td>[fold3] loss</td><td>0.0839</td></tr><tr><td>[fold3] lr</td><td>0.0</td></tr><tr><td>[fold4] loss</td><td>0.09529</td></tr><tr><td>[fold4] lr</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">microsoft/deberta-v3-large</strong>: <a href=\"https://wandb.ai/rashmi/FeedbackPrize3/runs/2aq9z4qq\" target=\"_blank\">https://wandb.ai/rashmi/FeedbackPrize3/runs/2aq9z4qq</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221116_220751-2aq9z4qq/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    def get_result(oof_df):\n",
    "        labels = oof_df[true_cols].values\n",
    "        preds = oof_df[pred_cols].values\n",
    "        score = get_score(labels, preds)\n",
    "        LOGGER.info(f'Score: {score:<.4f}')\n",
    "    \n",
    "    if CFG.train:\n",
    "        oof_df = pd.DataFrame()\n",
    "        for fold in range(CFG.n_fold):\n",
    "            if fold in CFG.trn_fold:\n",
    "                _oof_df = train_loop(df_folds, fold)\n",
    "                oof_df = pd.concat([oof_df, _oof_df])\n",
    "                _oof_df.to_csv(OUTPUT_DIR+f'oof_df{fold}.csv',index=False)\n",
    "                LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
    "                get_result(_oof_df)\n",
    "        oof_df = oof_df.reset_index(drop=True)\n",
    "        LOGGER.info(f\"========== CV ==========\")\n",
    "        get_result(oof_df)\n",
    "        oof_df.to_pickle(OUTPUT_DIR+'oof_df.pkl')\n",
    "        oof_df.to_csv(OUTPUT_DIR+'oof_df.csv',index=False)\n",
    "        \n",
    "    if CFG.wandb:\n",
    "        wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1663873473094,
     "user": {
      "displayName": "Rashmi Banthia",
      "userId": "08241869107709835428"
     },
     "user_tz": 240
    },
    "id": "1T7zzr_v-lWD",
    "outputId": "9d2e7a77-f934-4646-9d2e-7acf2d5c9cd2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/home/rashmi/Documents/kaggle/feedback3//src/models_exp117a_PL_9/tokenizer/tokenizer_config.json',\n",
       " '/home/rashmi/Documents/kaggle/feedback3//src/models_exp117a_PL_9/tokenizer/special_tokens_map.json',\n",
       " '/home/rashmi/Documents/kaggle/feedback3//src/models_exp117a_PL_9/tokenizer/spm.model',\n",
       " '/home/rashmi/Documents/kaggle/feedback3//src/models_exp117a_PL_9/tokenizer/added_tokens.json',\n",
       " '/home/rashmi/Documents/kaggle/feedback3//src/models_exp117a_PL_9/tokenizer/tokenizer.json')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CFG.tokenizer.save_pretrained(OUTPUT_DIR+'tokenizer/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1663873473427,
     "user": {
      "displayName": "Rashmi Banthia",
      "userId": "08241869107709835428"
     },
     "user_tz": 240
    },
    "id": "th8dmobR9EsC",
    "outputId": "ac5398ce-7ecc-4f3c-b85e-acd452ed858d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Nov 17 03:55:01 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 520.56.06    Driver Version: 520.56.06    CUDA Version: 11.8     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0 Off |                  Off |\n",
      "| 31%   47C    P2    72W / 450W |  10847MiB / 24564MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1111      G   /usr/lib/xorg/Xorg                 35MiB |\n",
      "|    0   N/A  N/A      1652      G   /usr/lib/xorg/Xorg                133MiB |\n",
      "|    0   N/A  N/A      1777      G   /usr/bin/gnome-shell               15MiB |\n",
      "|    0   N/A  N/A      3132      G   ...RendererForSitePerProcess       46MiB |\n",
      "|    0   N/A  N/A     75906      C   ...onda3/envs/fb3/bin/python    10594MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "Cx_DLr6W9E6A"
   },
   "outputs": [],
   "source": [
    "if colab:\n",
    "    from google.colab import runtime\n",
    "    runtime.unassign()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMqo+MDr8otuVetj6ZX/EuF",
   "collapsed_sections": [],
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3.9.13 ('fb3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "c56114763813c638e2fbb3b0f1bc1e4aa2cca20915871caf5011a76fc9be7be5"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "00cb0f09326f48648bc77717defcbed4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "02853e01c2c34d0f971302091ba489de": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "037f022ba7ba4191b0421562f8432320": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1389b90c58d5417ea8da9c183f6c8ea0",
      "max": 2464616,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_84a0247a3c80472ba8f42a17b13772a5",
      "value": 2464616
     }
    },
    "09d48089a9cb491a884907c5fb0cd321": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0c635c6632524abdb4025e3d34729683": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0d7eecf8f99848ea9c23756c223d34be": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "11fc2df7b97045c280b9bd9192468142": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5ca9836401c74fde83c7ee389957b344",
       "IPY_MODEL_4d45f897a07f4b0f872e01982bdced73"
      ],
      "layout": "IPY_MODEL_8d4a249fb2e24ddcaeb576a265fea475"
     }
    },
    "1389b90c58d5417ea8da9c183f6c8ea0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "17ac416ac3764b2ab31fafd66e6b63f4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "20005452fb7a4fcbb812da475138f4b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a117379727864b86bc3f92743fd46bb4",
      "placeholder": "​",
      "style": "IPY_MODEL_657c1434e09642758450169035fbd250",
      "value": " 2.46M/2.46M [00:00&lt;00:00, 24.8MB/s]"
     }
    },
    "2160a30916b44bde803b27ab7e1c0764": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ef291d1776eb4dbb97e2ad476e372c0a",
      "placeholder": "​",
      "style": "IPY_MODEL_f19414fc4d044c6e8612f31c2c834be4",
      "value": " 0/0 [00:00&lt;?, ?it/s]"
     }
    },
    "23f6b46983dc4451b2c4246046719b29": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bfde2b802d83416db5dfd57fcc2d563e",
      "placeholder": "​",
      "style": "IPY_MODEL_3c6043d1f6a14957b137d103046809d9",
      "value": ""
     }
    },
    "29aa0cc29eb14cc5a546cb6d759e2edf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fb22f13fdb474f1793c59e0cd6b13980",
      "max": 580,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_09d48089a9cb491a884907c5fb0cd321",
      "value": 580
     }
    },
    "2a07d5dcc2584e92a6f584ab4bd7079a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4aa057ca69a4470fb003053cdb812e3b",
       "IPY_MODEL_b4809140491c4af39356fc63510e359c",
       "IPY_MODEL_c9252a2b164a4ab8808570dcbf4fe33f"
      ],
      "layout": "IPY_MODEL_b1de1521292b40b3a43143af2a3e74b3"
     }
    },
    "2d8a6a93f4304304991d799e3a5b41e9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "386d12e9047e4463ac23eee35656025a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3c6043d1f6a14957b137d103046809d9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "422dbda576e84f6fbb7165f9c056dca2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4a604395aadc4f6b88d69a09078b7b63": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_64126e0a2a8e45e191f7564dc9b20cda",
      "placeholder": "​",
      "style": "IPY_MODEL_e9b72bce0ad244ee848df3b7501e2447",
      "value": "Downloading: 100%"
     }
    },
    "4aa057ca69a4470fb003053cdb812e3b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dcc9a9d2f8374a57bd576072c02e579a",
      "placeholder": "​",
      "style": "IPY_MODEL_0d7eecf8f99848ea9c23756c223d34be",
      "value": "Downloading: 100%"
     }
    },
    "4d45f897a07f4b0f872e01982bdced73": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_df5ee3563bf14108adf9ab1d861b9e4e",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6e57c54cacce47799611d716ff70f52a",
      "value": 1
     }
    },
    "5a5e59e351f941cf9b099e566eaa8693": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5ca9836401c74fde83c7ee389957b344": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2d8a6a93f4304304991d799e3a5b41e9",
      "placeholder": "​",
      "style": "IPY_MODEL_422dbda576e84f6fbb7165f9c056dca2",
      "value": "6.275 MB of 6.275 MB uploaded (0.000 MB deduped)\r"
     }
    },
    "64126e0a2a8e45e191f7564dc9b20cda": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "657c1434e09642758450169035fbd250": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "67ccfd480cc84e51ae6e3a81e160a2ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6de2ce67f2ba44cbbbc7c9877f6bbdd5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d1942a9b9c5a4d18b6bf90b2626ffefc",
       "IPY_MODEL_037f022ba7ba4191b0421562f8432320",
       "IPY_MODEL_20005452fb7a4fcbb812da475138f4b6"
      ],
      "layout": "IPY_MODEL_386d12e9047e4463ac23eee35656025a"
     }
    },
    "6e57c54cacce47799611d716ff70f52a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6f7952c1509d49099a0597e659ce5714": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "76d156eff0174e2b8b24d08b42bcf226": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "786737122d5141008f877783f44c6de4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4a604395aadc4f6b88d69a09078b7b63",
       "IPY_MODEL_29aa0cc29eb14cc5a546cb6d759e2edf",
       "IPY_MODEL_7e3a87338f1045bea1473b81b5a22566"
      ],
      "layout": "IPY_MODEL_a162e763f30941f484e6c75870a379cf"
     }
    },
    "7d63101f3e784294babe163546b61ec4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7e3a87338f1045bea1473b81b5a22566": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8c2122b040554d3781cf1164176d8b95",
      "placeholder": "​",
      "style": "IPY_MODEL_02853e01c2c34d0f971302091ba489de",
      "value": " 580/580 [00:00&lt;00:00, 23.8kB/s]"
     }
    },
    "8493f01d50ce4baa87643e47574aa12c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "84a0247a3c80472ba8f42a17b13772a5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "88728d80d4ef411e939dc5a21633b4ef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bfc1f40195904b829481005969009522",
      "max": 52,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_00cb0f09326f48648bc77717defcbed4",
      "value": 52
     }
    },
    "8c2122b040554d3781cf1164176d8b95": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8d4a249fb2e24ddcaeb576a265fea475": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "901d751c9df543e0bdf8a2f27be1e8ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c4552d78739243ac91711e6fbcd971e9",
       "IPY_MODEL_88728d80d4ef411e939dc5a21633b4ef",
       "IPY_MODEL_f1550ac128f1452a8276a8b05f87ec08"
      ],
      "layout": "IPY_MODEL_e9a0915b711a4fb3a219dcb5aa2c8a72"
     }
    },
    "93c3f000ef5a45b3862685d0ac6492fe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_23f6b46983dc4451b2c4246046719b29",
       "IPY_MODEL_94d72c0994df48df95ef6d0d14128262",
       "IPY_MODEL_2160a30916b44bde803b27ab7e1c0764"
      ],
      "layout": "IPY_MODEL_8493f01d50ce4baa87643e47574aa12c"
     }
    },
    "94d72c0994df48df95ef6d0d14128262": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_17ac416ac3764b2ab31fafd66e6b63f4",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_de56444578ff470cba1e93d40147c3aa",
      "value": 0
     }
    },
    "a0bf989572ed45869d4f3048baf9e37a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a117379727864b86bc3f92743fd46bb4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a162e763f30941f484e6c75870a379cf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ae9a9998768047bbb2188527d56af1da": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b1de1521292b40b3a43143af2a3e74b3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b4809140491c4af39356fc63510e359c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5a5e59e351f941cf9b099e566eaa8693",
      "max": 873673253,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6f7952c1509d49099a0597e659ce5714",
      "value": 873673253
     }
    },
    "b6835dfe966347a0b1e085777d1d4aaa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bfc1f40195904b829481005969009522": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bfde2b802d83416db5dfd57fcc2d563e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c4552d78739243ac91711e6fbcd971e9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b6835dfe966347a0b1e085777d1d4aaa",
      "placeholder": "​",
      "style": "IPY_MODEL_67ccfd480cc84e51ae6e3a81e160a2ed",
      "value": "Downloading: 100%"
     }
    },
    "c9252a2b164a4ab8808570dcbf4fe33f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a0bf989572ed45869d4f3048baf9e37a",
      "placeholder": "​",
      "style": "IPY_MODEL_0c635c6632524abdb4025e3d34729683",
      "value": " 874M/874M [00:13&lt;00:00, 65.0MB/s]"
     }
    },
    "d1942a9b9c5a4d18b6bf90b2626ffefc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7d63101f3e784294babe163546b61ec4",
      "placeholder": "​",
      "style": "IPY_MODEL_f7a2b7f7d0964fcca88c4a821797de51",
      "value": "Downloading: 100%"
     }
    },
    "dcc9a9d2f8374a57bd576072c02e579a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "de56444578ff470cba1e93d40147c3aa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "df5ee3563bf14108adf9ab1d861b9e4e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e9a0915b711a4fb3a219dcb5aa2c8a72": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e9b72bce0ad244ee848df3b7501e2447": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ef291d1776eb4dbb97e2ad476e372c0a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f1550ac128f1452a8276a8b05f87ec08": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_76d156eff0174e2b8b24d08b42bcf226",
      "placeholder": "​",
      "style": "IPY_MODEL_ae9a9998768047bbb2188527d56af1da",
      "value": " 52.0/52.0 [00:00&lt;00:00, 2.26kB/s]"
     }
    },
    "f19414fc4d044c6e8612f31c2c834be4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f7a2b7f7d0964fcca88c4a821797de51": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fb22f13fdb474f1793c59e0cd6b13980": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
